#!/usr/bin/env python3
"""
Command Dispatch Interface - ãƒ­ãƒ¼ã‚«ãƒ«LLMæŒ‡æ®å®˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
æŠ€è¡“ä½œæ¥­ã®æŒ‡ç¤ºãƒ»ç®¡ç†ãƒ»æ‰¿èªã«ç‰¹åŒ–ã—ãŸæŒ‡æ®å®˜å‹LLMã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
"""

import asyncio
import json
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
from dataclasses import dataclass
from enum import Enum

from ..core.config import LLMConfig
from ..core.models import Task, TaskPriority


class CommandType(Enum):
    """æŒ‡æ®å‘½ä»¤ã‚¿ã‚¤ãƒ—"""
    ANALYZE_REQUIREMENTS = "analyze_requirements"
    CREATE_SPECIFICATION = "create_specification"
    IMPLEMENT_CODE = "implement_code"
    CREATE_TESTS = "create_tests"
    GENERATE_DOCS = "generate_docs"
    REVIEW_QUALITY = "review_quality"


@dataclass
class CommandDirective:
    """æŒ‡æ®å®˜ã‹ã‚‰ã®æŒ‡ç¤º"""
    command_id: str
    command_type: CommandType
    target_agent: str  # "claude_code", "local_executor"
    instruction: str
    context: Dict[str, Any]
    priority: str
    expected_deliverables: List[str]
    success_criteria: List[str]
    constraints: List[str]
    timestamp: datetime


@dataclass
class ExecutionReport:
    """å®Ÿè¡Œè€…ã‹ã‚‰ã®å ±å‘Š"""
    command_id: str
    agent_id: str
    status: str  # "completed", "failed", "in_progress"
    deliverables: Dict[str, Any]
    execution_time: float
    quality_metrics: Dict[str, float]
    issues_encountered: List[str]
    recommendations: List[str]
    timestamp: datetime


@dataclass
class StrategicDecision:
    """æˆ¦ç•¥çš„åˆ¤æ–­çµæœ"""
    decision_type: str
    decision: str
    reasoning: str
    next_actions: List[CommandDirective]
    risk_assessment: Dict[str, str]
    resource_allocation: Dict[str, Any]


class CommandDispatchInterface:
    """æŒ‡æ®å®˜å‹ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    def __init__(self, config: LLMConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # æŒ‡æ®å®˜è¨­å®š
        self.command_history: List[CommandDirective] = []
        self.execution_reports: List[ExecutionReport] = []
        self.current_campaign_id = None
        
        # æˆ¦ç•¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.max_concurrent_commands = 3
        self.quality_threshold = 0.85
        self.risk_tolerance = "medium"
    
    async def initiate_strategic_campaign(self, task: Task) -> str:
        """æˆ¦ç•¥ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®é–‹å§‹"""
        campaign_id = f"campaign_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.current_campaign_id = campaign_id
        
        self.logger.info(f"ğŸ–ï¸ æˆ¦ç•¥ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³é–‹å§‹: {campaign_id}")
        self.logger.info(f"ğŸ“‹ ä½œæˆ¦ç›®æ¨™: {task.description}")
        
        return campaign_id
    
    async def analyze_mission_requirements(self, task: Task) -> StrategicDecision:
        """ä½œæˆ¦è¦æ±‚åˆ†æã¨æˆ¦ç•¥ç«‹æ¡ˆ"""
        self.logger.info("ğŸ¯ ä½œæˆ¦è¦æ±‚åˆ†æä¸­...")
        
        analysis_prompt = f"""
        ã‚ãªãŸã¯çµŒé¨“è±Šå¯ŒãªæŠ€è¡“ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæŒ‡æ®å®˜ã§ã™ã€‚
        ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã®æˆ¦ç•¥çš„åˆ†æã‚’è¡Œã„ã€å®Ÿè¡Œè¨ˆç”»ã‚’ç«‹æ¡ˆã—ã¦ãã ã•ã„ã€‚

        **ã‚¿ã‚¹ã‚¯è©³ç´°:**
        - èª¬æ˜: {task.description}
        - å„ªå…ˆåº¦: {task.priority.value}
        - è¦ä»¶: {json.dumps(task.requirements, ensure_ascii=False)}
        - å“è³ªç›®æ¨™: {task.estimated_quality}

        **åˆ†æé …ç›®:**
        1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æˆ¦ç•¥çš„é‡è¦åº¦
        2. æŠ€è¡“çš„è¤‡é›‘åº¦ã¨ãƒªã‚¹ã‚¯
        3. ãƒªã‚½ãƒ¼ã‚¹è¦æ±‚äºˆæ¸¬
        4. å®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚ºã®åˆ†å‰²
        5. å“è³ªç®¡ç†æ–¹é‡

        **å‡ºåŠ›å½¢å¼ (JSON):**
        {{
          "strategic_priority": "high|medium|low",
          "complexity_assessment": "complex|moderate|simple",
          "execution_phases": ["phase1", "phase2", "phase3"],
          "risk_factors": ["risk1", "risk2"],
          "resource_requirements": {{"æ™‚é–“": "2-4æ™‚é–“", "æŠ€è¡“è€…": "1å"}},
          "quality_strategy": "å³å¯†å“è³ªç®¡ç†|æ¨™æº–å“è³ªç®¡ç†|åŸºæœ¬å“è³ªç®¡ç†",
          "success_metrics": ["metric1", "metric2"]
        }}
        """
        
        try:
            response = await self._strategic_consultation(analysis_prompt)
            strategic_data = json.loads(response)
            
            # æˆ¦ç•¥çš„åˆ¤æ–­ã‚’åŸºã«æŒ‡ä»¤ã‚’ç”Ÿæˆ
            next_actions = self._generate_initial_commands(task, strategic_data)
            
            decision = StrategicDecision(
                decision_type="mission_analysis",
                decision=f"æˆ¦ç•¥: {strategic_data.get('quality_strategy', 'æ¨™æº–å“è³ªç®¡ç†')}",
                reasoning=f"è¤‡é›‘åº¦: {strategic_data.get('complexity_assessment', 'ä¸­ç¨‹åº¦')}ã€å„ªå…ˆåº¦: {strategic_data.get('strategic_priority', 'ä¸­')}",
                next_actions=next_actions,
                risk_assessment={
                    "technical_risk": strategic_data.get('complexity_assessment', 'moderate'),
                    "timeline_risk": "ä½" if len(strategic_data.get('execution_phases', [])) <= 3 else "ä¸­",
                    "quality_risk": "ä½" if task.estimated_quality <= 0.8 else "ä¸­"
                },
                resource_allocation=strategic_data.get('resource_requirements', {})
            )
            
            self.logger.info(f"âœ… æˆ¦ç•¥åˆ†æå®Œäº†: {decision.decision}")
            return decision
            
        except Exception as e:
            self.logger.error(f"æˆ¦ç•¥åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥
            return self._generate_fallback_strategy(task)
    
    def _generate_initial_commands(self, task: Task, strategic_data: Dict) -> List[CommandDirective]:
        """åˆæœŸæŒ‡ä»¤ç”Ÿæˆ"""
        commands = []
        timestamp = datetime.now()
        
        # ç¬¬1ãƒ•ã‚§ãƒ¼ã‚º: æŠ€è¡“è¦ä»¶åˆ†ææŒ‡ä»¤
        commands.append(CommandDirective(
            command_id=f"{self.current_campaign_id}_cmd_001",
            command_type=CommandType.ANALYZE_REQUIREMENTS,
            target_agent="claude_code",
            instruction=f"""
            ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã®æŠ€è¡“è¦ä»¶ã‚’è©³ç´°ã«åˆ†æã—ã¦ãã ã•ã„ï¼š

            **ã‚¿ã‚¹ã‚¯**: {task.description}
            **è¦ä»¶**: {json.dumps(task.requirements, ensure_ascii=False)}

            **åˆ†æé …ç›®**:
            1. æ©Ÿèƒ½è¦ä»¶ã®è©³ç´°åŒ–
            2. éæ©Ÿèƒ½è¦ä»¶ã®ç‰¹å®š
            3. æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã®é¸å®š
            4. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¦ä»¶
            5. ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¦ä»¶
            6. ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¦ä»¶
            7. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶
            8. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶

            è©³ç´°ãªæŠ€è¡“è¦ä»¶åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            """,
            context={
                "task_id": task.id,
                "priority": task.priority.value,
                "quality_target": task.estimated_quality,
                "strategic_approach": strategic_data.get('quality_strategy', 'æ¨™æº–å“è³ªç®¡ç†')
            },
            priority="high",
            expected_deliverables=[
                "æŠ€è¡“è¦ä»¶åˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
                "æ©Ÿèƒ½è¦ä»¶ãƒªã‚¹ãƒˆ",
                "éæ©Ÿèƒ½è¦ä»¶ãƒªã‚¹ãƒˆ",
                "æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ææ¡ˆ",
                "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦"
            ],
            success_criteria=[
                "ã™ã¹ã¦ã®è¦ä»¶ãŒå…·ä½“çš„ã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹",
                "æŠ€è¡“çš„å®Ÿç¾å¯èƒ½æ€§ãŒæ¤œè¨¼ã•ã‚Œã¦ã„ã‚‹",
                "å“è³ªç›®æ¨™ã‚’æº€ãŸã™ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹"
            ],
            constraints=[
                f"å“è³ªç›®æ¨™: {task.estimated_quality}ä»¥ä¸Š",
                "æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®äº’æ›æ€§ç¶­æŒ",
                "å®Ÿè£…å¯èƒ½ãªæŠ€è¡“ã®ã¿ä½¿ç”¨"
            ],
            timestamp=timestamp
        ))
        
        return commands
    
    async def issue_command(self, directive: CommandDirective) -> str:
        """æŒ‡ä»¤ç™ºä»¤"""
        self.logger.info(f"ğŸ“¢ æŒ‡ä»¤ç™ºä»¤: {directive.command_type.value} -> {directive.target_agent}")
        self.logger.info(f"ğŸ¯ æŒ‡ä»¤ID: {directive.command_id}")
        
        self.command_history.append(directive)
        
        return directive.command_id
    
    async def receive_execution_report(self, report: ExecutionReport) -> StrategicDecision:
        """å®Ÿè¡Œå ±å‘Šå—é ˜ã¨æ¬¡ã®æˆ¦ç•¥åˆ¤æ–­"""
        self.logger.info(f"ğŸ“‹ å®Ÿè¡Œå ±å‘Šå—é ˜: {report.command_id} - {report.status}")
        
        self.execution_reports.append(report)
        
        # å ±å‘Šå†…å®¹ã‚’è©•ä¾¡ã—ã€æ¬¡ã®æˆ¦ç•¥ã‚’æ±ºå®š
        evaluation_prompt = f"""
        æŒ‡æ®å®˜ã¨ã—ã¦å®Ÿè¡Œå ±å‘Šã‚’è©•ä¾¡ã—ã€æ¬¡ã®æˆ¦ç•¥ã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚

        **å®Ÿè¡Œå ±å‘Šå†…å®¹:**
        - ã‚³ãƒãƒ³ãƒ‰ID: {report.command_id}
        - å®Ÿè¡Œè€…: {report.agent_id}
        - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {report.status}
        - å®Ÿè¡Œæ™‚é–“: {report.execution_time}ç§’
        - å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹: {json.dumps(report.quality_metrics, ensure_ascii=False)}
        - æˆæœç‰©: {len(report.deliverables)}é …ç›®
        - èª²é¡Œ: {report.issues_encountered}
        - æ¨å¥¨äº‹é …: {report.recommendations}

        **åˆ¤æ–­é …ç›®:**
        1. å®Ÿè¡Œçµæœã®å“è³ªè©•ä¾¡
        2. æ¬¡ãƒ•ã‚§ãƒ¼ã‚ºé€²è¡Œå¯å¦
        3. è¿½åŠ æŒ‡ç¤ºã®å¿…è¦æ€§
        4. ãƒªã‚¹ã‚¯è¦å› ã®è©•ä¾¡

        **å‡ºåŠ›å½¢å¼ (JSON):**
        {{
          "overall_assessment": "excellent|good|acceptable|poor",
          "proceed_to_next_phase": true|false,
          "quality_score": 0.0-1.0,
          "next_command_type": "create_specification|implement_code|review_quality|abort",
          "specific_instructions": "æ¬¡ã®å…·ä½“çš„æŒ‡ç¤ºå†…å®¹",
          "risk_mitigation": "ãƒªã‚¹ã‚¯è»½æ¸›ç­–"
        }}
        """
        
        try:
            response = await self._strategic_consultation(evaluation_prompt)
            evaluation = json.loads(response)
            
            # æ¬¡ã®æŒ‡ä»¤ã‚’ç”Ÿæˆ
            next_actions = self._generate_next_command(report, evaluation)
            
            decision = StrategicDecision(
                decision_type="execution_evaluation",
                decision=f"è©•ä¾¡: {evaluation.get('overall_assessment', 'acceptable')}ã€æ¬¡ãƒ•ã‚§ãƒ¼ã‚º: {'é€²è¡Œ' if evaluation.get('proceed_to_next_phase', True) else 'ä¿ç•™'}",
                reasoning=f"å“è³ªã‚¹ã‚³ã‚¢: {evaluation.get('quality_score', 0.8)}, èª²é¡Œæ•°: {len(report.issues_encountered)}",
                next_actions=next_actions,
                risk_assessment={
                    "current_quality": str(evaluation.get('quality_score', 0.8)),
                    "execution_risk": "ä½" if report.status == "completed" else "é«˜",
                    "timeline_risk": "ä½" if report.execution_time < 300 else "ä¸­"
                },
                resource_allocation={}
            )
            
            return decision
            
        except Exception as e:
            self.logger.error(f"æˆ¦ç•¥è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_fallback_decision(report)
    
    def _generate_next_command(self, report: ExecutionReport, evaluation: Dict) -> List[CommandDirective]:
        """æ¬¡ã®æŒ‡ä»¤ç”Ÿæˆ"""
        if not evaluation.get('proceed_to_next_phase', True):
            return []
        
        next_cmd_type = evaluation.get('next_command_type', 'create_specification')
        
        if next_cmd_type == "create_specification":
            return [self._create_specification_command(report, evaluation)]
        elif next_cmd_type == "implement_code":
            return [self._create_implementation_command(report, evaluation)]
        elif next_cmd_type == "review_quality":
            return [self._create_review_command(report, evaluation)]
        
        return []
    
    def _create_specification_command(self, report: ExecutionReport, evaluation: Dict) -> CommandDirective:
        """ä»•æ§˜æ›¸ä½œæˆæŒ‡ä»¤"""
        return CommandDirective(
            command_id=f"{self.current_campaign_id}_spec_{datetime.now().strftime('%H%M%S')}",
            command_type=CommandType.CREATE_SPECIFICATION,
            target_agent="claude_code",
            instruction=f"""
            å‰å›ã®æŠ€è¡“è¦ä»¶åˆ†æçµæœã‚’åŸºã«ã€è©³ç´°ãªæŠ€è¡“ä»•æ§˜æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

            **å‰å›ã®æˆæœç‰©:**
            {json.dumps(report.deliverables, ensure_ascii=False, indent=2)}

            **è¿½åŠ æŒ‡ç¤º:**
            {evaluation.get('specific_instructions', 'æ¨™æº–çš„ãªä»•æ§˜æ›¸ä½œæˆæ‰‹é †ã«å¾“ã£ã¦ãã ã•ã„')}

            **ä½œæˆã™ã‚‹ä»•æ§˜æ›¸:**
            1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
            2. ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ï¼ˆæ©Ÿèƒ½è¦ä»¶ãƒ»éæ©Ÿèƒ½è¦ä»¶ï¼‰
            3. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ
            4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ
            5. APIä»•æ§˜
            6. å®Ÿè£…ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
            7. ãƒ†ã‚¹ãƒˆæˆ¦ç•¥
            8. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹é †

            GitHub Spec Kitæ¨™æº–ã«æº–æ‹ ã—ãŸé«˜å“è³ªãªä»•æ§˜æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            """,
            context=report.deliverables,
            priority="high",
            expected_deliverables=[
                "å®Œå…¨ãªæŠ€è¡“ä»•æ§˜æ›¸",
                "å®Ÿè£…ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³",
                "ãƒ†ã‚¹ãƒˆè¨ˆç”»",
                "ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹é †"
            ],
            success_criteria=[
                "ã™ã¹ã¦ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè©³ç´°ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹",
                "å®Ÿè£…å¯èƒ½ãªãƒ¬ãƒ™ãƒ«ã®å…·ä½“æ€§ãŒã‚ã‚‹",
                "å“è³ªç›®æ¨™ã‚’æº€ãŸã™ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒå«ã¾ã‚Œã¦ã„ã‚‹"
            ],
            constraints=[
                "GitHub Spec Kitæ¨™æº–æº–æ‹ ",
                "å®Ÿè£…å¯èƒ½æ€§ã‚’é‡è¦–",
                "ä¿å®ˆæ€§ã‚’è€ƒæ…®ã—ãŸè¨­è¨ˆ"
            ],
            timestamp=datetime.now()
        )
    
    def _create_implementation_command(self, report: ExecutionReport, evaluation: Dict) -> CommandDirective:
        """å®Ÿè£…æŒ‡ä»¤"""
        return CommandDirective(
            command_id=f"{self.current_campaign_id}_impl_{datetime.now().strftime('%H%M%S')}",
            command_type=CommandType.IMPLEMENT_CODE,
            target_agent="claude_code",
            instruction=f"""
            ä½œæˆã•ã‚ŒãŸä»•æ§˜æ›¸ã«åŸºã¥ã„ã¦å®Ÿè£…ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

            **ä»•æ§˜æ›¸æƒ…å ±:**
            {json.dumps(report.deliverables, ensure_ascii=False, indent=2)}

            **å®Ÿè£…æŒ‡ç¤º:**
            {evaluation.get('specific_instructions', 'ä»•æ§˜æ›¸ã«å¾“ã£ã¦æ®µéšçš„ã«å®Ÿè£…ã—ã¦ãã ã•ã„')}

            **å®Ÿè£…é …ç›®:**
            1. ã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®Ÿè£…
            2. ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…
            3. API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å®Ÿè£…
            4. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®å®Ÿè£…
            5. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
            6. å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ä½œæˆ

            é«˜å“è³ªã§ä¿å®ˆæ€§ã®é«˜ã„ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            """,
            context=report.deliverables,
            priority="high",
            expected_deliverables=[
                "å®Ÿè£…ã‚³ãƒ¼ãƒ‰ä¸€å¼",
                "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«",
                "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ",
                "åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«"
            ],
            success_criteria=[
                "ä»•æ§˜æ›¸é€šã‚Šã®æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹",
                "ã‚³ãƒ¼ãƒ‰å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã‚‹",
                "é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒå«ã¾ã‚Œã¦ã„ã‚‹"
            ],
            constraints=[
                "æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¨ã®äº’æ›æ€§ç¶­æŒ",
                "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹æº–æ‹ ",
                "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶é”æˆ"
            ],
            timestamp=datetime.now()
        )
    
    async def _strategic_consultation(self, prompt: str) -> str:
        """æˆ¦ç•¥çš„ç›¸è«‡ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMå‘¼ã³å‡ºã—ï¼‰"""
        if not self.config.enabled:
            return self._generate_fallback_strategic_response(prompt)
        
        # å®Ÿéš›ã®ãƒ­ãƒ¼ã‚«ãƒ«LLMå‘¼ã³å‡ºã—ï¼ˆç°¡ç•¥åŒ–ï¼‰
        # å®Ÿè£…ã§ã¯ local_llm_interface ã® _call_llm ã‚’ä½¿ç”¨
        await asyncio.sleep(0.1)  # æ¨¡æ“¬å‡¦ç†æ™‚é–“
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯é©åˆ‡ãªLLMå¿œç­”ï¼‰
        return self._generate_fallback_strategic_response(prompt)
    
    def _generate_fallback_strategic_response(self, prompt: str) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥å¿œç­”"""
        if "ä½œæˆ¦è¦æ±‚åˆ†æ" in prompt:
            return json.dumps({
                "strategic_priority": "medium",
                "complexity_assessment": "moderate",
                "execution_phases": ["analysis", "specification", "implementation"],
                "risk_factors": ["æŠ€è¡“çš„è¤‡é›‘æ€§", "æ™‚é–“åˆ¶ç´„"],
                "resource_requirements": {"æ™‚é–“": "2-4æ™‚é–“", "æŠ€è¡“è€…": "1å"},
                "quality_strategy": "æ¨™æº–å“è³ªç®¡ç†",
                "success_metrics": ["æ©Ÿèƒ½å®Ÿè£…å®Œäº†", "å“è³ªåŸºæº–é”æˆ"]
            }, ensure_ascii=False)
        elif "å®Ÿè¡Œå ±å‘Š" in prompt:
            return json.dumps({
                "overall_assessment": "good",
                "proceed_to_next_phase": True,
                "quality_score": 0.85,
                "next_command_type": "create_specification",
                "specific_instructions": "æ¨™æº–çš„ãªä»•æ§˜æ›¸ä½œæˆæ‰‹é †ã«å¾“ã£ã¦ãã ã•ã„",
                "risk_mitigation": "å®šæœŸçš„ãªå“è³ªãƒã‚§ãƒƒã‚¯ã‚’å®Ÿæ–½"
            }, ensure_ascii=False)
        
        return '{"status": "ready", "action": "proceed"}'
    
    def _generate_fallback_strategy(self, task: Task) -> StrategicDecision:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥"""
        return StrategicDecision(
            decision_type="fallback_analysis",
            decision="æ¨™æº–å“è³ªç®¡ç†æˆ¦ç•¥ã‚’é©ç”¨",
            reasoning="æˆ¦ç•¥åˆ†æã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€æ¨™æº–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨",
            next_actions=self._generate_initial_commands(task, {"quality_strategy": "æ¨™æº–å“è³ªç®¡ç†"}),
            risk_assessment={"technical_risk": "medium", "timeline_risk": "low"},
            resource_allocation={"æ™‚é–“": "2-4æ™‚é–“", "æŠ€è¡“è€…": "1å"}
        )
    
    def _generate_fallback_decision(self, report: ExecutionReport) -> StrategicDecision:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¤æ–­"""
        return StrategicDecision(
            decision_type="fallback_evaluation",
            decision="æ¬¡ãƒ•ã‚§ãƒ¼ã‚ºã«é€²è¡Œ",
            reasoning="è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€æ¨™æº–é€²è¡Œã‚’æ¡ç”¨",
            next_actions=self._generate_next_command(report, {"proceed_to_next_phase": True, "next_command_type": "create_specification"}),
            risk_assessment={"execution_risk": "medium"},
            resource_allocation={}
        )
    
    async def finalize_campaign(self) -> Dict[str, Any]:
        """ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³çµ‚äº†"""
        self.logger.info(f"ğŸ æˆ¦ç•¥ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å®Œäº†: {self.current_campaign_id}")
        
        campaign_summary = {
            "campaign_id": self.current_campaign_id,
            "total_commands": len(self.command_history),
            "successful_executions": len([r for r in self.execution_reports if r.status == "completed"]),
            "average_execution_time": sum(r.execution_time for r in self.execution_reports) / len(self.execution_reports) if self.execution_reports else 0,
            "overall_quality": sum(r.quality_metrics.get('overall', 0.8) for r in self.execution_reports) / len(self.execution_reports) if self.execution_reports else 0.8
        }
        
        return campaign_summary


# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
async def create_command_dispatcher(config: LLMConfig) -> CommandDispatchInterface:
    """æŒ‡æ®å®˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°"""
    return CommandDispatchInterface(config)