#!/usr/bin/env python3
"""
Code Validator - ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã®å“è³ªæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ã‚’ã‚¼ãƒ­ã«ã™ã‚‹ãŸã‚ã®è‡ªå‹•æ¤œè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
"""

import ast
import asyncio
import importlib.util
import logging
import subprocess
import sys
import tempfile
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from datetime import datetime


@dataclass
class ValidationResult:
    """æ¤œè¨¼çµæœ"""
    file_path: str
    is_valid: bool
    syntax_errors: List[str]
    import_errors: List[str]
    runtime_errors: List[str]
    quality_score: float
    recommendations: List[str]
    execution_test_passed: bool


@dataclass
class ValidationReport:
    """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆå…¨ä½“"""
    project_path: str
    total_files: int
    valid_files: int
    overall_quality: float
    validation_results: List[ValidationResult]
    critical_issues: List[str]
    recommendations: List[str]
    validation_time: float


class CodeValidator:
    """ç”Ÿæˆã‚³ãƒ¼ãƒ‰å“è³ªæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.validation_history: List[ValidationReport] = []
    
    async def validate_generated_project(self, project_path: str) -> ValidationReport:
        """ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®æ¤œè¨¼"""
        self.logger.info(f"ğŸ” ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå“è³ªæ¤œè¨¼é–‹å§‹: {project_path}")
        start_time = datetime.now()
        
        project_path = Path(project_path)
        python_files = list(project_path.rglob("*.py"))
        
        validation_results = []
        critical_issues = []
        
        for py_file in python_files:
            self.logger.info(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼: {py_file.name}")
            result = await self._validate_single_file(py_file)
            validation_results.append(result)
            
            if not result.is_valid:
                critical_issues.extend(result.syntax_errors)
                critical_issues.extend(result.import_errors)
                critical_issues.extend(result.runtime_errors)
        
        # å…¨ä½“å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
        valid_files = len([r for r in validation_results if r.is_valid])
        overall_quality = sum(r.quality_score for r in validation_results) / len(validation_results) if validation_results else 0.0
        
        # å…¨ä½“æ¨å¥¨äº‹é …
        recommendations = self._generate_project_recommendations(validation_results)
        
        validation_time = (datetime.now() - start_time).total_seconds()
        
        report = ValidationReport(
            project_path=str(project_path),
            total_files=len(python_files),
            valid_files=valid_files,
            overall_quality=overall_quality,
            validation_results=validation_results,
            critical_issues=critical_issues,
            recommendations=recommendations,
            validation_time=validation_time
        )
        
        self.validation_history.append(report)
        
        self.logger.info(f"âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¤œè¨¼å®Œäº†: å“è³ªã‚¹ã‚³ã‚¢ {overall_quality:.2f}")
        return report
    
    async def _validate_single_file(self, file_path: Path) -> ValidationResult:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æ¤œè¨¼"""
        syntax_errors = []
        import_errors = []
        runtime_errors = []
        quality_score = 0.0
        recommendations = []
        execution_test_passed = False
        
        try:
            # Step 1: æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
            syntax_errors = self._check_syntax(file_path)
            
            # Step 2: ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
            if not syntax_errors:
                import_errors = await self._check_imports(file_path)
            
            # Step 3: å®Ÿè¡Œãƒ†ã‚¹ãƒˆï¼ˆãƒ¡ã‚¤ãƒ³å®Ÿè¡Œå¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼‰
            if not syntax_errors and not import_errors:
                execution_test_passed, runtime_errors = await self._test_execution(file_path)
            
            # Step 4: å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
            quality_score = self._calculate_quality_score(
                file_path, syntax_errors, import_errors, runtime_errors, execution_test_passed
            )
            
            # Step 5: æ¨å¥¨äº‹é …ç”Ÿæˆ
            recommendations = self._generate_file_recommendations(
                file_path, syntax_errors, import_errors, runtime_errors
            )
            
        except Exception as e:
            self.logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
            syntax_errors.append(f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        
        is_valid = len(syntax_errors) == 0 and len(import_errors) == 0 and len(runtime_errors) == 0
        
        return ValidationResult(
            file_path=str(file_path),
            is_valid=is_valid,
            syntax_errors=syntax_errors,
            import_errors=import_errors,
            runtime_errors=runtime_errors,
            quality_score=quality_score,
            recommendations=recommendations,
            execution_test_passed=execution_test_passed
        )
    
    def _check_syntax(self, file_path: Path) -> List[str]:
        """Pythonæ§‹æ–‡ãƒã‚§ãƒƒã‚¯"""
        errors = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                source_code = f.read()
            
            # AST ãƒ‘ãƒ¼ã‚¹
            ast.parse(source_code, filename=str(file_path))
            
        except SyntaxError as e:
            errors.append(f"æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ (è¡Œ {e.lineno}): {e.msg}")
        except Exception as e:
            errors.append(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        return errors
    
    async def _check_imports(self, file_path: Path) -> List[str]:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯"""
        errors = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                source_code = f.read()
            
            # ASTã‚’ä½¿ã£ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‚’æŠ½å‡º
            tree = ast.parse(source_code)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        try:
                            importlib.import_module(alias.name)
                        except ImportError as e:
                            errors.append(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {alias.name} - {e}")
                
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        try:
                            importlib.import_module(node.module)
                        except ImportError as e:
                            errors.append(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {node.module} - {e}")
        
        except Exception as e:
            errors.append(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        
        return errors
    
    async def _test_execution(self, file_path: Path) -> Tuple[bool, List[str]]:
        """å®Ÿè¡Œãƒ†ã‚¹ãƒˆï¼ˆå®‰å…¨ãªç’°å¢ƒã§ï¼‰"""
        errors = []
        
        # ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã®ã¿ãƒ†ã‚¹ãƒˆ
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if 'if __name__ == "__main__"' not in content:
                return True, []  # ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ­ãƒƒã‚¯ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            
            # ä¸€æ™‚çš„ãªå®Ÿè¡Œç’°å¢ƒã§ãƒ†ã‚¹ãƒˆ
            process = await asyncio.create_subprocess_exec(
                sys.executable, str(file_path),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=file_path.parent
            )
            
            try:
                stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=10.0)
                
                if process.returncode != 0:
                    error_output = stderr.decode('utf-8')
                    errors.append(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ (çµ‚äº†ã‚³ãƒ¼ãƒ‰ {process.returncode}): {error_output}")
                    return False, errors
                
                return True, []
                
            except asyncio.TimeoutError:
                process.kill()
                errors.append("å®Ÿè¡Œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (10ç§’)")
                return False, errors
        
        except Exception as e:
            errors.append(f"å®Ÿè¡Œãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False, errors
    
    def _calculate_quality_score(
        self, 
        file_path: Path, 
        syntax_errors: List[str], 
        import_errors: List[str], 
        runtime_errors: List[str],
        execution_test_passed: bool
    ) -> float:
        """å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—"""
        base_score = 1.0
        
        # ã‚¨ãƒ©ãƒ¼ã«å¿œã˜ã¦æ¸›ç‚¹
        base_score -= len(syntax_errors) * 0.3  # æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã¯é‡å¤§
        base_score -= len(import_errors) * 0.2  # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ã¯ä¸­ç¨‹åº¦
        base_score -= len(runtime_errors) * 0.25  # å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã¯é‡å¤§
        
        # å®Ÿè¡Œãƒ†ã‚¹ãƒˆå¤±æ•—æ™‚ã¯è¿½åŠ æ¸›ç‚¹
        if not execution_test_passed:
            base_score -= 0.1
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒœãƒ¼ãƒŠã‚¹ï¼ˆé©åˆ‡ãªé•·ã•ï¼‰
        try:
            file_size = file_path.stat().st_size
            if 1000 <= file_size <= 10000:  # 1KB-10KB ãŒé©åˆ‡
                base_score += 0.05
        except:
            pass
        
        return max(0.0, min(1.0, base_score))
    
    def _generate_file_recommendations(
        self,
        file_path: Path,
        syntax_errors: List[str],
        import_errors: List[str], 
        runtime_errors: List[str]
    ) -> List[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥æ¨å¥¨äº‹é …"""
        recommendations = []
        
        if syntax_errors:
            recommendations.append("æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„")
        
        if import_errors:
            recommendations.append("ä¸è¶³ã—ã¦ã„ã‚‹ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")
            recommendations.append("requirements.txtã®æ›´æ–°ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if runtime_errors:
            recommendations.append("å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ã®åŸå› ã‚’èª¿æŸ»ã—ä¿®æ­£ã—ã¦ãã ã•ã„")
            recommendations.append("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®è¿½åŠ ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨äº‹é …
        if file_path.name.endswith('_test.py'):
            recommendations.append("ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®è¿½åŠ ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if file_path.name == 'main.py':
            recommendations.append("é©åˆ‡ãªãƒ­ã‚°è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
        return recommendations
    
    def _generate_project_recommendations(self, validation_results: List[ValidationResult]) -> List[str]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®æ¨å¥¨äº‹é …"""
        recommendations = []
        
        total_files = len(validation_results)
        invalid_files = len([r for r in validation_results if not r.is_valid])
        
        if invalid_files > 0:
            recommendations.append(f"{invalid_files}/{total_files} ãƒ•ã‚¡ã‚¤ãƒ«ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚å„ªå…ˆçš„ã«ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
        
        avg_quality = sum(r.quality_score for r in validation_results) / total_files if total_files > 0 else 0
        
        if avg_quality < 0.8:
            recommendations.append("å…¨ä½“çš„ãªå“è³ªå‘ä¸ŠãŒå¿…è¦ã§ã™ã€‚ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚")
        
        # å…±é€šã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®š
        all_import_errors = []
        for result in validation_results:
            all_import_errors.extend(result.import_errors)
        
        if len(all_import_errors) > 3:
            recommendations.append("å¤šæ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚requirements.txtã®è¦‹ç›´ã—ãŒå¿…è¦ã§ã™ã€‚")
        
        return recommendations
    
    async def generate_validation_report(self, report: ValidationReport, output_path: str = None) -> str:
        """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        if not output_path:
            output_path = f"validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        report_content = f"""# ã‚³ãƒ¼ãƒ‰å“è³ªæ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ

## æ¤œè¨¼æ¦‚è¦
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: {report.project_path}
- **æ¤œè¨¼æ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ¤œè¨¼æ™‚é–“**: {report.validation_time:.2f}ç§’
- **å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {report.total_files}
- **æœ‰åŠ¹ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {report.valid_files}
- **å…¨ä½“å“è³ªã‚¹ã‚³ã‚¢**: {report.overall_quality:.2f}

## æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼
{'âœ… å…¨ãƒ•ã‚¡ã‚¤ãƒ«æ­£å¸¸' if report.valid_files == report.total_files else f'âš ï¸ {report.total_files - report.valid_files}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å•é¡ŒãŒã‚ã‚Šã¾ã™'}

## ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥è©³ç´°çµæœ

"""
        
        for result in report.validation_results:
            status = "âœ… æ­£å¸¸" if result.is_valid else "âŒ è¦ä¿®æ­£"
            report_content += f"""### {Path(result.file_path).name} - {status}
- **å“è³ªã‚¹ã‚³ã‚¢**: {result.quality_score:.2f}
- **å®Ÿè¡Œãƒ†ã‚¹ãƒˆ**: {'âœ… æˆåŠŸ' if result.execution_test_passed else 'âŒ å¤±æ•—'}

"""
            
            if result.syntax_errors:
                report_content += f"""**æ§‹æ–‡ã‚¨ãƒ©ãƒ¼**:
{chr(10).join(f"- {error}" for error in result.syntax_errors)}

"""
            
            if result.import_errors:
                report_content += f"""**ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼**:
{chr(10).join(f"- {error}" for error in result.import_errors)}

"""
            
            if result.runtime_errors:
                report_content += f"""**å®Ÿè¡Œã‚¨ãƒ©ãƒ¼**:
{chr(10).join(f"- {error}" for error in result.runtime_errors)}

"""
            
            if result.recommendations:
                report_content += f"""**æ¨å¥¨äº‹é …**:
{chr(10).join(f"- {rec}" for rec in result.recommendations)}

"""
        
        if report.critical_issues:
            report_content += f"""## ğŸš¨ é‡è¦ãªå•é¡Œ

{chr(10).join(f"- {issue}" for issue in report.critical_issues)}

"""
        
        if report.recommendations:
            report_content += f"""## ğŸ“‹ æ¨å¥¨äº‹é …

{chr(10).join(f"- {rec}" for rec in report.recommendations)}

"""
        
        report_content += f"""## ç·è©•

{'ğŸ‰ ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã™ã€‚' if report.overall_quality >= 0.8 else 'âš ï¸ ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¯æ”¹å–„ãŒå¿…è¦ãªç®‡æ‰€ãŒã‚ã‚Šã¾ã™ã€‚'}

**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**:
1. ä¸Šè¨˜ã®å•é¡Œã‚’ä¿®æ­£ã—ã¦ãã ã•ã„
2. ä¿®æ­£å¾Œã«å†åº¦æ¤œè¨¼ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„
3. å“è³ªã‚¹ã‚³ã‚¢0.8ä»¥ä¸Šã‚’ç›®æŒ‡ã—ã¦ãã ã•ã„

---
ç”Ÿæˆæ—¥æ™‚: {datetime.now().isoformat()}
"""
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        self.logger.info(f"ğŸ“„ æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {output_path}")
        return output_path


# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
async def validate_project(project_path: str) -> ValidationReport:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¤œè¨¼ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    validator = CodeValidator()
    return await validator.validate_generated_project(project_path)


# CLIå®Ÿè¡Œç”¨
async def main():
    """CLIå®Ÿè¡Œ"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ã‚³ãƒ¼ãƒ‰å“è³ªæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("project_path", help="æ¤œè¨¼ã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‘ã‚¹")
    parser.add_argument("--output", "-o", help="ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‘ã‚¹")
    
    args = parser.parse_args()
    
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    validator = CodeValidator()
    report = await validator.validate_generated_project(args.project_path)
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_path = await validator.generate_validation_report(report, args.output)
    
    print(f"\nğŸ” æ¤œè¨¼å®Œäº†!")
    print(f"ğŸ“Š å“è³ªã‚¹ã‚³ã‚¢: {report.overall_quality:.2f}")
    print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
    
    if report.overall_quality < 0.8:
        print("âš ï¸ å“è³ªåŸºæº–æœªé”ã€‚ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")
        sys.exit(1)
    else:
        print("âœ… å“è³ªåŸºæº–ã‚¯ãƒªã‚¢!")


if __name__ == "__main__":
    asyncio.run(main())