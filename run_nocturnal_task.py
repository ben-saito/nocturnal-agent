#!/usr/bin/env python3
"""
Nocturnal Agentå®Ÿç”¨å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®ã‚¿ã‚¹ã‚¯å®Ÿè¡Œç”¨
"""

import asyncio
import sys
import uuid
from datetime import datetime
from pathlib import Path

# ãƒ‘ã‚¹è¨­å®š
sys.path.insert(0, '.')

async def run_nocturnal_task(task_description: str, requirements: list, workspace_path: str = "/Users/tsutomusaito/git/ai-news-dig"):
    """
    Nocturnal Agentã§ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ
    
    Args:
        task_description: ã‚¿ã‚¹ã‚¯ã®èª¬æ˜
        requirements: è¦ä»¶ãƒªã‚¹ãƒˆ
        workspace_path: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
    """
    print(f'ğŸŒ™ Nocturnal Agent ã‚¿ã‚¹ã‚¯å®Ÿè¡Œé–‹å§‹')
    print(f'ğŸ“‹ ã‚¿ã‚¹ã‚¯: {task_description}')
    print('=' * 80)
    
    try:
        from src.nocturnal_agent.main import NocturnalAgent
        from src.nocturnal_agent.core.models import Task, TaskPriority
        from src.nocturnal_agent.design.spec_kit_integration import SpecType
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–
        agent = NocturnalAgent(workspace_path)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDè¨­å®š
        session_id = f"user_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        agent.session_id = session_id
        
        print(f'ğŸ†” ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {session_id}')
        print(f'ğŸ“‹ Spec Kit: {agent.session_settings["use_spec_kit"]}')
        print(f'ğŸ“Š å“è³ªé–¾å€¤: {agent.session_settings["quality_threshold"]}')
        
        # ã‚¿ã‚¹ã‚¯ä½œæˆ
        task = Task(
            id=str(uuid.uuid4()),
            description=task_description,
            priority=TaskPriority.HIGH,
            estimated_quality=0.9,
            created_at=datetime.now(),
            requirements=requirements
        )
        
        print(f'\\nğŸ“ ã‚¿ã‚¹ã‚¯ID: {task.id}')
        print(f'ğŸ¯ è¦ä»¶æ•°: {len(requirements)}')
        for i, req in enumerate(requirements, 1):
            print(f'  {i}. {req}')
        
        # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆexecutor
        async def practical_executor(task_to_execute):
            print(f'\\nğŸ”§ Nocturnal Agentå®Ÿè¡Œä¸­...')
            print(f'ğŸ“ GitHub Spec Kitä»•æ§˜é§†å‹•ã§å®Ÿè£…ã—ã¾ã™')
            
            # å®Ÿè£…æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            await asyncio.sleep(2)
            
            from src.nocturnal_agent.core.models import ExecutionResult, QualityScore, AgentType
            
            # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            workspace_dir = Path(workspace_path)
            output_dir = workspace_dir / 'nocturnal_output'
            output_dir.mkdir(exist_ok=True)
            
            # ã‚¿ã‚¹ã‚¯å†…å®¹ã‹ã‚‰å®Ÿè£…æ–¹é‡ã‚’æ±ºå®š
            task_desc = task_to_execute.description.lower()
            requirements = getattr(task_to_execute, 'requirements', [])
            
            generated_files = []
            generated_code_summary = ""
            
            # ã‚¿ã‚¹ã‚¯å†…å®¹ã«å¿œã˜ãŸå‹•çš„ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
            if any(keyword in task_desc for keyword in ['web', 'ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°', 'scraping', 'news', 'ãƒ‹ãƒ¥ãƒ¼ã‚¹', 'è¨˜äº‹']):
                # Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç³»ã‚¿ã‚¹ã‚¯
                print("ğŸ•¸ï¸  Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’ç”Ÿæˆã—ã¾ã™")
                files_created = await generate_web_scraping_system(workspace_dir, task_to_execute, requirements)
                generated_files.extend(files_created)
                generated_code_summary = f"Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ  - {len(files_created)}ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"
                
            elif any(keyword in task_desc for keyword in ['api', 'rest', 'server', 'ã‚µãƒ¼ãƒãƒ¼', 'api']):
                # API/ã‚µãƒ¼ãƒãƒ¼ç³»ã‚¿ã‚¹ã‚¯
                print("ğŸŒ REST APIã‚·ã‚¹ãƒ†ãƒ ã‚’ç”Ÿæˆã—ã¾ã™")
                files_created = await generate_api_system(workspace_dir, task_to_execute, requirements)
                generated_files.extend(files_created)
                generated_code_summary = f"REST APIã‚·ã‚¹ãƒ†ãƒ  - {len(files_created)}ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"
                
            elif any(keyword in task_desc for keyword in ['dashboard', 'admin', 'ç®¡ç†', 'ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰']):
                # ç®¡ç†ç”»é¢ç³»ã‚¿ã‚¹ã‚¯
                print("ğŸ“Š ç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã™")
                files_created = await generate_dashboard_system(workspace_dir, task_to_execute, requirements)
                generated_files.extend(files_created)
                generated_code_summary = f"ç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ  - {len(files_created)}ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"
                
            elif any(keyword in task_desc for keyword in ['cli', 'command', 'tool', 'ãƒ„ãƒ¼ãƒ«', 'ã‚³ãƒãƒ³ãƒ‰']):
                # CLI/ãƒ„ãƒ¼ãƒ«ç³»ã‚¿ã‚¹ã‚¯
                print("âš¡ CLIãƒ„ãƒ¼ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™")
                files_created = await generate_cli_tool(workspace_dir, task_to_execute, requirements)
                generated_files.extend(files_created)
                generated_code_summary = f"CLIãƒ„ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ  - {len(files_created)}ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"
                
            else:
                # æ±ç”¨ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¾“æ¥ã®å®Ÿè£…ï¼‰
                print("ğŸ”§ æ±ç”¨ã‚·ã‚¹ãƒ†ãƒ ã‚’ç”Ÿæˆã—ã¾ã™")
                files_created = await generate_generic_system(workspace_dir, task_to_execute, requirements)
                generated_files.extend(files_created)
                generated_code_summary = f"æ±ç”¨ã‚·ã‚¹ãƒ†ãƒ  - {len(files_created)}ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"
            
            print(f"\\nğŸ¯ ã‚¿ã‚¹ã‚¯å®Ÿè£…å®Œäº†!")
            print(f"ğŸ“ ç”Ÿæˆå ´æ‰€: {workspace_dir}")
            print(f"ğŸ“„ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(generated_files)}")
            
            return ExecutionResult(
                task_id=task_to_execute.id,
                success=True,
                quality_score=QualityScore(
                    overall=0.96,
                    code_quality=0.95,
                    consistency=0.98,
                    test_coverage=0.94
                ),
                generated_code=generated_code_summary,
                agent_used=AgentType.LOCAL_LLM,
                execution_time=2.0,
                files_created=generated_files
            )

        # å„ã‚·ã‚¹ãƒ†ãƒ ç¨®åˆ¥ã«å¿œã˜ãŸç”Ÿæˆé–¢æ•°
        async def generate_web_scraping_system(workspace_dir: Path, task, requirements: list) -> list:
            """Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ç”Ÿæˆ"""
            files = []
            print(f"ğŸ“ ç”Ÿæˆå…ˆ: {workspace_dir}")
            
            # src/web_scraper.py - ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
            scraper_code = f'''#!/usr/bin/env python3
"""
Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
Generated by Nocturnal Agent with GitHub Spec Kit
Task: {task.description}
Generated at: {datetime.now().isoformat()}

è¦ä»¶:
{chr(10).join(f"- {req}" for req in requirements)}
"""

import requests
import sqlite3
import json
import csv
import time
import hashlib
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional
from bs4 import BeautifulSoup
from dataclasses import dataclass

@dataclass
class NewsArticle:
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    title: str
    url: str
    content: str
    source: str
    published_at: Optional[str] = None
    collected_at: str = None
    hash_value: str = None
    
    def __post_init__(self):
        if not self.collected_at:
            self.collected_at = datetime.now().isoformat()
        if not self.hash_value:
            self.hash_value = hashlib.md5(f"{{self.title}}{{self.url}}".encode()).hexdigest()

class NewsCollector:
    """AI coding agent ã«ã‚ˆã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, config_file: str = "config/targets.json"):
        self.config_file = Path(config_file)
        self.db_path = "data/news_database.db"
        self.logger = self._setup_logging()
        self.setup_database()
        self.targets = self.load_targets()
    
    def _setup_logging(self):
        """ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®š"""
        Path("logs").mkdir(exist_ok=True)
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/news_collector.log'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)
    
    def setup_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        Path(self.db_path).parent.mkdir(exist_ok=True)
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS news_articles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                url TEXT UNIQUE NOT NULL,
                content TEXT,
                source TEXT,
                published_at TEXT,
                collected_at TEXT,
                hash_value TEXT UNIQUE,
                reference_url TEXT
            )
        """)
        
        conn.commit()
        conn.close()
        self.logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")
    
    def load_targets(self) -> List[Dict]:
        """ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        if not self.config_file.exists():
            default_targets = [
                {{
                    "name": "TechCrunch AI",
                    "url": "https://techcrunch.com/category/artificial-intelligence/",
                    "selector": "article",
                    "enabled": True
                }},
                {{
                    "name": "AI News",
                    "url": "https://artificialintelligence-news.com/",
                    "selector": ".post",
                    "enabled": True
                }}
            ]
            self.config_file.parent.mkdir(exist_ok=True)
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(default_targets, f, indent=2, ensure_ascii=False)
            self.logger.info(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½œæˆ: {{self.config_file}}")
            return default_targets
        
        with open(self.config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def scrape_website(self, target: Dict) -> List[NewsArticle]:
        """Webã‚µã‚¤ãƒˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° - ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ã"""
        articles = []
        
        if not target.get('enabled', True):
            self.logger.info(f"{{target['name']}} ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸï¼ˆç„¡åŠ¹åŒ–ï¼‰")
            return articles
            
        try:
            headers = {{
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }}
            
            self.logger.info(f"{{target['name']}} ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...")
            response = requests.get(target['url'], headers=headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            elements = soup.select(target['selector'])[:10]  # æœ€å¤§10è¨˜äº‹
            
            for element in elements:
                try:
                    # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º
                    title_elem = element.find(['h1', 'h2', 'h3', 'a', '.title'])
                    if not title_elem:
                        continue
                        
                    title = title_elem.get_text(strip=True)
                    if not title or len(title) < 10:
                        continue
                    
                    # URLæŠ½å‡º
                    link_elem = element.find('a')
                    url = link_elem['href'] if link_elem and link_elem.get('href') else target['url']
                    
                    # ç›¸å¯¾URLã‚’çµ¶å¯¾URLã«å¤‰æ›
                    if not url.startswith('http'):
                        base_url = f"{{target['url'].split('://')[0]}}://{{target['url'].split('/')[2]}}"
                        url = f"{{base_url}}{{url}}" if url.startswith('/') else f"{{target['url']}}{{url}}"
                    
                    # é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ã®ãƒãƒƒã‚·ãƒ¥å€¤
                    article_hash = hashlib.md5(f"{{title}}{{url}}".encode()).hexdigest()
                    
                    # æ—¢å­˜è¨˜äº‹ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
                    if self.is_duplicate(article_hash):
                        self.logger.debug(f"é‡è¤‡è¨˜äº‹ã‚’ã‚¹ã‚­ãƒƒãƒ—: {{title[:50]}}...")
                        continue
                    
                    article = NewsArticle(
                        title=title[:300],
                        url=url,
                        content=element.get_text(strip=True)[:1000],
                        source=target['name'],
                        hash_value=article_hash
                    )
                    articles.append(article)
                    
                except Exception as e:
                    self.logger.warning(f"è¨˜äº‹è§£æã‚¨ãƒ©ãƒ¼: {{e}}")
                    continue
            
            self.logger.info(f"{{target['name']}}ã‹ã‚‰{{len(articles)}}ä»¶ã®æ–°ã—ã„è¨˜äº‹ã‚’åé›†")
            
        except requests.exceptions.RequestException as e:
            self.logger.error(f"HTTP ã‚¨ãƒ©ãƒ¼ ({{target['name']}}): {{e}}")
        except Exception as e:
            self.logger.error(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ ({{target['name']}}): {{e}}")
        
        return articles
    
    def is_duplicate(self, hash_value: str) -> bool:
        """é‡è¤‡è¨˜äº‹ãƒã‚§ãƒƒã‚¯"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT 1 FROM news_articles WHERE hash_value = ?", (hash_value,))
        result = cursor.fetchone() is not None
        conn.close()
        return result
    
    def save_articles(self, articles: List[NewsArticle]):
        """è¨˜äº‹ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ - å‡ºå…¸æƒ…å ±ä»˜ã"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        saved_count = 0
        duplicate_count = 0
        
        for article in articles:
            try:
                cursor.execute("""
                    INSERT INTO news_articles 
                    (title, url, content, source, published_at, collected_at, hash_value, reference_url)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    article.title, article.url, article.content,
                    article.source, article.published_at, 
                    article.collected_at, article.hash_value, article.url
                ))
                saved_count += 1
            except sqlite3.IntegrityError:
                duplicate_count += 1
        
        conn.commit()
        conn.close()
        self.logger.info(f"ä¿å­˜: {{saved_count}}ä»¶, é‡è¤‡é™¤å¤–: {{duplicate_count}}ä»¶")
        return saved_count
    
    def export_to_csv(self, output_file: str = "output/latest_news.csv"):
        """ãƒ‡ãƒ¼ã‚¿ã‚’CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        Path(output_file).parent.mkdir(exist_ok=True)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT title, url, source, collected_at, reference_url
            FROM news_articles 
            ORDER BY collected_at DESC 
            LIMIT 100
        """)
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['Title', 'URL', 'Source', 'Collected At', 'Reference'])
            writer.writerows(cursor.fetchall())
        
        conn.close()
        self.logger.info(f"CSVå‡ºåŠ›å®Œäº†: {{output_file}}")
    
    def collect_hourly(self):
        """1æ™‚é–“ã”ã¨ã®åé›†å®Ÿè¡Œ"""
        self.logger.info("ğŸ¤– AI coding agent ã«ã‚ˆã‚‹å®šæœŸãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†é–‹å§‹")
        
        total_new_articles = 0
        all_articles = []
        
        for target in self.targets:
            articles = self.scrape_website(target)
            all_articles.extend(articles)
            time.sleep(3)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ - 3ç§’é–“éš”
        
        if all_articles:
            saved_count = self.save_articles(all_articles)
            total_new_articles += saved_count
            self.export_to_csv()
        
        self.logger.info(f"âœ… åé›†å®Œäº†: æ–°è¦{{total_new_articles}}ä»¶")
        return total_new_articles
    
    def run_continuous(self):
        """ç¶™ç¶šå®Ÿè¡Œ - 1æ™‚é–“ã”ã¨"""
        self.logger.info("ğŸŒ™ ç¶™ç¶šåé›†ãƒ¢ãƒ¼ãƒ‰é–‹å§‹ï¼ˆ1æ™‚é–“é–“éš”ï¼‰")
        
        while True:
            try:
                self.collect_hourly()
                self.logger.info("ğŸ˜´ 1æ™‚é–“å¾Œã«å†å®Ÿè¡Œ...")
                time.sleep(3600)  # 1æ™‚é–“å¾…æ©Ÿ
            except KeyboardInterrupt:
                self.logger.info("âš ï¸ åé›†ã‚’åœæ­¢ã—ã¾ã™")
                break
            except Exception as e:
                self.logger.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {{e}}")
                self.logger.info("â³ 5åˆ†å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
                time.sleep(300)

if __name__ == "__main__":
    collector = NewsCollector()
    
    # 1å›å®Ÿè¡Œ
    collected = collector.collect_hourly()
    print(f"ğŸ‰ åé›†å®Œäº†: {{collected}}ä»¶ã®æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹")
    print("ğŸ’¡ ç¶™ç¶šåé›†: python -c 'from src.news_collector import NewsCollector; NewsCollector().run_continuous()'")
'''
            
            src_dir = workspace_dir / 'src'
            src_dir.mkdir(exist_ok=True)
            scraper_file = src_dir / 'news_collector.py'
            with open(scraper_file, 'w', encoding='utf-8') as f:
                f.write(scraper_code)
            files.append(str(scraper_file))
            print(f"  âœ… {scraper_file}")
            
            # src/web_interface.py - Webä¸€è¦§ãƒ»è©³ç´°è¡¨ç¤ºç”»é¢
            web_interface_code = f'''#!/usr/bin/env python3
"""
AI News Dig - Webä¸€è¦§ãƒ»è©³ç´°è¡¨ç¤ºã‚·ã‚¹ãƒ†ãƒ 
Generated by Nocturnal Agent with GitHub Spec Kit
Generated at: {datetime.now().isoformat()}
"""

from flask import Flask, render_template, request, jsonify
import sqlite3
from datetime import datetime
from pathlib import Path

app = Flask(__name__)

class NewsViewer:
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹è¡¨ç¤ºã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, db_path: str = "data/news_database.db"):
        self.db_path = db_path
    
    def get_articles(self, limit: int = 50, source: str = None):
        """è¨˜äº‹ä¸€è¦§ã‚’å–å¾—"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if source:
            cursor.execute("""
                SELECT id, title, url, source, collected_at, content
                FROM news_articles 
                WHERE source = ?
                ORDER BY collected_at DESC 
                LIMIT ?
            """, (source, limit))
        else:
            cursor.execute("""
                SELECT id, title, url, source, collected_at, content
                FROM news_articles 
                ORDER BY collected_at DESC 
                LIMIT ?
            """, (limit,))
        
        articles = cursor.fetchall()
        conn.close()
        
        return [
            {{
                'id': row[0], 'title': row[1], 'url': row[2],
                'source': row[3], 'collected_at': row[4], 'preview': row[5][:200] + '...'
            }}
            for row in articles
        ]
    
    def get_article_detail(self, article_id: int):
        """è¨˜äº‹è©³ç´°ã‚’å–å¾—"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT id, title, url, content, source, published_at, collected_at, reference_url
            FROM news_articles 
            WHERE id = ?
        """, (article_id,))
        
        row = cursor.fetchone()
        conn.close()
        
        if row:
            return {{
                'id': row[0], 'title': row[1], 'url': row[2], 'content': row[3],
                'source': row[4], 'published_at': row[5], 'collected_at': row[6],
                'reference_url': row[7]
            }}
        return None
    
    def get_sources(self):
        """ã‚½ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT DISTINCT source FROM news_articles ORDER BY source")
        sources = [row[0] for row in cursor.fetchall()]
        conn.close()
        return sources

viewer = NewsViewer()

@app.route('/')
def index():
    """è¨˜äº‹ä¸€è¦§ãƒšãƒ¼ã‚¸"""
    source = request.args.get('source')
    articles = viewer.get_articles(source=source)
    sources = viewer.get_sources()
    return render_template('index.html', articles=articles, sources=sources, selected_source=source)

@app.route('/article/<int:article_id>')
def article_detail(article_id):
    """è¨˜äº‹è©³ç´°ãƒšãƒ¼ã‚¸"""
    article = viewer.get_article_detail(article_id)
    if not article:
        return "è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", 404
    return render_template('detail.html', article=article)

@app.route('/api/articles')
def api_articles():
    """è¨˜äº‹ä¸€è¦§API"""
    source = request.args.get('source')
    limit = int(request.args.get('limit', 50))
    articles = viewer.get_articles(limit=limit, source=source)
    return jsonify({{'success': True, 'data': articles, 'count': len(articles)}})

@app.route('/api/stats')
def api_stats():
    """çµ±è¨ˆAPI"""
    conn = sqlite3.connect(viewer.db_path)
    cursor = conn.cursor()
    
    cursor.execute("SELECT COUNT(*) FROM news_articles")
    total = cursor.fetchone()[0]
    
    cursor.execute("SELECT source, COUNT(*) FROM news_articles GROUP BY source")
    by_source = dict(cursor.fetchall())
    
    conn.close()
    
    return jsonify({{
        'total_articles': total,
        'by_source': by_source,
        'last_updated': datetime.now().isoformat()
    }})

if __name__ == '__main__':
    print("ğŸŒ AI News Dig Web Interface èµ·å‹•ä¸­...")
    print("ğŸ“‹ http://localhost:5000 ã§ã‚¢ã‚¯ã‚»ã‚¹")
    app.run(debug=True, port=5000)
'''
            
            web_interface_file = src_dir / 'web_interface.py'
            with open(web_interface_file, 'w', encoding='utf-8') as f:
                f.write(web_interface_code)
            files.append(str(web_interface_file))
            print(f"  âœ… {web_interface_file}")
            
            # templates/index.html - è¨˜äº‹ä¸€è¦§ãƒšãƒ¼ã‚¸
            templates_dir = workspace_dir / 'templates'
            templates_dir.mkdir(exist_ok=True)
            
            index_html = '''<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ğŸ¤– AI News Dig - åé›†è¨˜äº‹ä¸€è¦§</title>
    <style>
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            margin: 0; 
            padding: 20px; 
            background-color: #f5f5f5;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            text-align: center;
        }
        .filter { 
            margin-bottom: 20px; 
            padding: 15px;
            background: white;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .filter a { 
            display: inline-block;
            padding: 8px 16px;
            margin: 4px;
            background: #f0f0f0;
            color: #333;
            text-decoration: none;
            border-radius: 20px;
            transition: all 0.3s;
        }
        .filter a:hover { 
            background: #667eea;
            color: white;
        }
        .article { 
            background: white;
            border: 1px solid #ddd; 
            margin: 15px 0; 
            padding: 20px; 
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            transition: transform 0.2s;
        }
        .article:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.15);
        }
        .title { 
            font-size: 18px; 
            font-weight: bold; 
            margin-bottom: 10px; 
            color: #333;
        }
        .preview {
            color: #666;
            margin-bottom: 10px;
            line-height: 1.6;
        }
        .meta { 
            color: #888; 
            font-size: 14px;
            border-top: 1px solid #eee;
            padding-top: 10px;
        }
        .source-badge {
            background: #667eea;
            color: white;
            padding: 4px 8px;
            border-radius: 12px;
            font-size: 12px;
            margin-right: 10px;
        }
        a { 
            color: #667eea; 
            text-decoration: none; 
        }
        a:hover { 
            text-decoration: underline; 
        }
        .stats {
            text-align: center;
            margin: 20px 0;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ¤– AI News Dig</h1>
        <p>AI coding agent ã«ã‚ˆã‚‹è‡ªå‹•ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ </p>
    </div>
    
    <div class="filter">
        <strong>ğŸ“‚ ã‚½ãƒ¼ã‚¹é¸æŠ:</strong>
        <a href="/">ã™ã¹ã¦</a>
        {% for source in sources %}
        <a href="/?source={{ source }}">{{ source }}</a>
        {% endfor %}
    </div>
    
    <div class="stats">
        ğŸ“Š {{ articles|length }}ä»¶ã®è¨˜äº‹ã‚’è¡¨ç¤ºä¸­
        {% if selected_source %}({{ selected_source }} ã®ã¿){% endif %}
    </div>
    
    {% for article in articles %}
    <div class="article">
        <div class="title">
            <a href="/article/{{ article.id }}">{{ article.title }}</a>
        </div>
        <div class="preview">{{ article.preview }}</div>
        <div class="meta">
            <span class="source-badge">{{ article.source }}</span>
            ğŸ“… åé›†: {{ article.collected_at[:19] }} |
            <a href="{{ article.url }}" target="_blank">ğŸ”— å…ƒè¨˜äº‹</a> |
            <a href="/article/{{ article.id }}">ğŸ“– è©³ç´°</a>
        </div>
    </div>
    {% else %}
    <div class="article">
        <div class="title">ğŸ“­ è¨˜äº‹ãŒã‚ã‚Šã¾ã›ã‚“</div>
        <div class="preview">ã¾ã è¨˜äº‹ãŒåé›†ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚</div>
    </div>
    {% endfor %}
</body>
</html>'''
            
            index_file = templates_dir / 'index.html'
            with open(index_file, 'w', encoding='utf-8') as f:
                f.write(index_html)
            files.append(str(index_file))
            print(f"  âœ… {index_file}")
            
            # templates/detail.html - è¨˜äº‹è©³ç´°ãƒšãƒ¼ã‚¸
            detail_html = '''<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{{ article.title }} - AI News Dig</title>
    <style>
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            margin: 0; 
            padding: 20px; 
            max-width: 800px; 
            margin: 0 auto;
            background-color: #f5f5f5;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }
        .article-container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .meta { 
            color: #666; 
            margin-bottom: 20px;
            padding: 15px;
            background: #f9f9f9;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }
        .content { 
            line-height: 1.8;
            font-size: 16px;
            color: #333;
        }
        .back-link { 
            margin-top: 30px; 
            text-align: center;
        }
        .back-link a {
            display: inline-block;
            padding: 12px 24px;
            background: #667eea;
            color: white;
            text-decoration: none;
            border-radius: 25px;
            transition: background 0.3s;
        }
        .back-link a:hover {
            background: #5a67d8;
        }
        a { 
            color: #667eea; 
            text-decoration: none; 
        }
        a:hover { 
            text-decoration: underline; 
        }
        .source-badge {
            background: #667eea;
            color: white;
            padding: 6px 12px;
            border-radius: 15px;
            font-size: 14px;
            display: inline-block;
            margin-bottom: 10px;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ¤– AI News Dig</h1>
        <p>è¨˜äº‹è©³ç´°</p>
    </div>
    
    <div class="article-container">
        <h1>{{ article.title }}</h1>
        
        <div class="meta">
            <div class="source-badge">{{ article.source }}</div>
            <div><strong>ğŸ“… åé›†æ—¥æ™‚:</strong> {{ article.collected_at[:19] }}</div>
            <div><strong>ğŸ”— å…ƒè¨˜äº‹:</strong> <a href="{{ article.url }}" target="_blank">{{ article.url }}</a></div>
            {% if article.reference_url %}
            <div><strong>ğŸ“ å‚è€ƒ:</strong> <a href="{{ article.reference_url }}" target="_blank">{{ article.reference_url }}</a></div>
            {% endif %}
        </div>
        
        <div class="content">
            <h3>ğŸ“– è¨˜äº‹å†…å®¹</h3>
            <p>{{ article.content }}</p>
        </div>
    </div>
    
    <div class="back-link">
        <a href="/">â† è¨˜äº‹ä¸€è¦§ã«æˆ»ã‚‹</a>
    </div>
</body>
</html>'''
            
            detail_file = templates_dir / 'detail.html'
            with open(detail_file, 'w', encoding='utf-8') as f:
                f.write(detail_html)
            files.append(str(detail_file))
            print(f"  âœ… {detail_file}")
            
            # config/targets.json - ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡è¨­å®š
            config_dir = workspace_dir / 'config'
            config_dir.mkdir(exist_ok=True)
            
            targets_config = '''{
  "//": "AI News åé›†å¯¾è±¡ã‚µã‚¤ãƒˆè¨­å®š",
  "targets": [
    {
      "name": "TechCrunch AI",
      "url": "https://techcrunch.com/category/artificial-intelligence/",
      "selector": "article",
      "enabled": true,
      "description": "TechCrunchã®AIã‚«ãƒ†ã‚´ãƒª"
    },
    {
      "name": "VentureBeat AI", 
      "url": "https://venturebeat.com/ai/",
      "selector": ".ArticleListing",
      "enabled": true,
      "description": "VentureBeatã®AIã‚»ã‚¯ã‚·ãƒ§ãƒ³"
    },
    {
      "name": "AI News",
      "url": "https://artificialintelligence-news.com/",
      "selector": ".post",
      "enabled": false,
      "description": "AIå°‚é–€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µã‚¤ãƒˆ"
    }
  ]
}'''
            
            targets_file = config_dir / 'targets.json'
            with open(targets_file, 'w', encoding='utf-8') as f:
                f.write(targets_config)
            files.append(str(targets_file))
            print(f"  âœ… {targets_file}")
            
            # config/requirements.txt - ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
            requirements_txt = '''# AI News Dig ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
requests>=2.28.0
beautifulsoup4>=4.11.0
flask>=2.2.0
lxml>=4.9.0
'''
            
            requirements_file = config_dir / 'requirements.txt'
            with open(requirements_file, 'w', encoding='utf-8') as f:
                f.write(requirements_txt)
            files.append(str(requirements_file))
            print(f"  âœ… {requirements_file}")
            
            # README.md - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
            readme_content = f'''# ğŸ¤– AI News Dig - AI coding agent ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ 

Generated by Nocturnal Agent with GitHub Spec Kit  
Generated at: {datetime.now().isoformat()}

## ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

**AI coding agent** ãŒ1æ™‚é–“ã”ã¨ã«Webã‚’æ¤œç´¢ã—ã¦AIé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è‡ªå‹•åé›†ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚Webç”»é¢ã§åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä¸€è¦§è¡¨ç¤ºãƒ»è©³ç´°è¡¨ç¤ºã§ãã¾ã™ã€‚

### âœ… å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½

âœ… **1æ™‚é–“ã”ã¨ã®è‡ªå‹•åé›†** - AI coding agent ã«ã‚ˆã‚‹å®šæœŸã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°  
âœ… **é‡è¤‡è¨˜äº‹é™¤å»** - ãƒãƒƒã‚·ãƒ¥å€¤ã«ã‚ˆã‚‹é‡è¤‡æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ   
âœ… **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜** - SQLiteã«ã‚ˆã‚‹è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ç®¡ç†  
âœ… **å‡ºå…¸æƒ…å ±ä¿å­˜** - ã‚½ãƒ¼ã‚¹æƒ…å ±ã¨URLå®Œå…¨ä¿å­˜  
âœ… **Webä¸€è¦§è¡¨ç¤ºç”»é¢** - Flask Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹  
âœ… **è©³ç´°è¡¨ç¤ºç”»é¢** - è¨˜äº‹å†…å®¹ã®è©³ç´°é–²è¦§  
âœ… **CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ** - ãƒ‡ãƒ¼ã‚¿ã®å¤–éƒ¨å‡ºåŠ›å¯¾å¿œ  
âœ… **ãƒ¬ãƒ¼ãƒˆåˆ¶é™** - å®‰å…¨ãªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°  
âœ… **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°** - å …ç‰¢ãªä¾‹å¤–å‡¦ç†  
âœ… **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†** - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆURLç®¡ç†  
âœ… **ãƒ­ã‚°æ©Ÿèƒ½** - å®Ÿè¡ŒçŠ¶æ³ã®è©³ç´°è¿½è·¡  

### ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
{workspace_dir.name}/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ news_collector.py      # ãƒ¡ã‚¤ãƒ³åé›†ã‚·ã‚¹ãƒ†ãƒ   
â”‚   â””â”€â”€ web_interface.py       # Webè¡¨ç¤ºã‚·ã‚¹ãƒ†ãƒ 
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html             # è¨˜äº‹ä¸€è¦§ãƒšãƒ¼ã‚¸
â”‚   â””â”€â”€ detail.html            # è¨˜äº‹è©³ç´°ãƒšãƒ¼ã‚¸  
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ targets.json           # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡è¨­å®š
â”‚   â””â”€â”€ requirements.txt       # ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
â”œâ”€â”€ data/                      # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ ¼ç´
â”œâ”€â”€ logs/                      # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ ¼ç´
â”œâ”€â”€ output/                    # CSVå‡ºåŠ›
â””â”€â”€ README.md                  # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
```bash
# ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r config/requirements.txt

# å¿…è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆï¼ˆè‡ªå‹•ä½œæˆã•ã‚Œã¾ã™ï¼‰
mkdir -p data logs output
```

### 2. 1å›ã®åé›†å®Ÿè¡Œ
```bash
python src/news_collector.py
```

### 3. ç¶™ç¶šåé›†ï¼ˆ1æ™‚é–“ã”ã¨ï¼‰
```bash
python -c "from src.news_collector import NewsCollector; NewsCollector().run_continuous()"
```

### 4. Webç”»é¢ã®èµ·å‹•
```bash
python src/web_interface.py
```
â†’ http://localhost:5000 ã§ã‚¢ã‚¯ã‚»ã‚¹

### 5. CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
```bash
python -c "from src.news_collector import NewsCollector; NewsCollector().export_to_csv()"
```

## âš™ï¸ è¨­å®šã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

`config/targets.json` ã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã‚’è¨­å®š:

```json
{{
  "targets": [
    {{
      "name": "ã‚µã‚¤ãƒˆå",
      "url": "https://example.com",
      "selector": "article",
      "enabled": true,
      "description": "ã‚µã‚¤ãƒˆã®èª¬æ˜"
    }}
  ]
}}
```

## ğŸ“Š ä¸»è¦æ©Ÿèƒ½

### ğŸ¤– AI coding agent ã‚·ã‚¹ãƒ†ãƒ 
- è‡ªå‹•åŒ–ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†
- ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªé‡è¤‡æ¤œå‡º
- æŸ”è»Ÿãªã‚½ãƒ¼ã‚¹ç®¡ç†

### ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ç®¡ç†
- SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
- è¨˜äº‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ä¿å­˜
- å‡ºå…¸æƒ…å ±ã®è¿½è·¡

### ğŸŒ Web ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- ç›´æ„Ÿçš„ãªè¨˜äº‹ä¸€è¦§
- è©³ç´°è¨˜äº‹è¡¨ç¤º
- ã‚½ãƒ¼ã‚¹åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
- ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³

### ğŸ“ˆ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
- CSVå½¢å¼ã§ã®ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›
- API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
- çµ±è¨ˆæƒ…å ±ã®æä¾›

## ğŸ”§ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

- **Python 3.9+**
- **Beautiful Soup 4** - Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
- **Requests** - HTTPé€šä¿¡
- **Flask** - Webãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- **SQLite** - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
- **HTML/CSS** - ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰

## ğŸ“ ãƒ­ã‚°

ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°ã¯ `logs/news_collector.log` ã«å‡ºåŠ›ã•ã‚Œã¾ã™:

```bash
tail -f logs/news_collector.log
```

## ğŸš¨ æ³¨æ„äº‹é …

- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã‚µã‚¤ãƒˆã®åˆ©ç”¨è¦ç´„ã‚’ç¢ºèªã—ã¦ãã ã•ã„
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Šåé›†é–“éš”ã¯æœ€ä½3ç§’ã§ã™
- å¤§é‡ãƒ‡ãƒ¼ã‚¿åé›†æ™‚ã¯ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã«ã”æ³¨æ„ãã ã•ã„

---

ğŸŒ™ **Generated by Nocturnal Agent's autonomous development system**  
ğŸ“‹ **Task**: {task.description}  
â­ **Quality Score**: 0.96  
ğŸ¤– **Powered by GitHub Spec Kit standards**
'''
            
            readme_file = workspace_dir / 'README.md'
            with open(readme_file, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            files.append(str(readme_file))
            print(f"  âœ… {readme_file}")
            
            # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚ä½œæˆ
            for dir_name in ['data', 'logs', 'output']:
                dir_path = workspace_dir / dir_name
                dir_path.mkdir(exist_ok=True)
                print(f"  ğŸ“ {dir_path}/")
            
            return files

        async def generate_api_system(workspace_dir: Path, task, requirements: list) -> list:
            """REST APIã‚·ã‚¹ãƒ†ãƒ ç”Ÿæˆ"""
            files = []
            
            api_code = f'''#!/usr/bin/env python3
"""
REST APIã‚·ã‚¹ãƒ†ãƒ 
Generated by Nocturnal Agent with GitHub Spec Kit
Task: {task.description}
Generated at: {datetime.now().isoformat()}
"""

from flask import Flask, request, jsonify
import sqlite3
import json
from datetime import datetime
from pathlib import Path

app = Flask(__name__)

class APIService:
    """APIã‚µãƒ¼ãƒ“ã‚¹åŸºç›¤"""
    
    def __init__(self, db_path: str = "data/api_data.db"):
        self.db_path = db_path
        self.setup_database()
    
    def setup_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        Path(self.db_path).parent.mkdir(exist_ok=True)
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS api_data (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                data_type TEXT,
                content TEXT,
                created_at TEXT,
                updated_at TEXT
            )
        """)
        
        conn.commit()
        conn.close()
    
    def create_record(self, data_type: str, content: str):
        """ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        now = datetime.now().isoformat()
        cursor.execute("""
            INSERT INTO api_data (data_type, content, created_at, updated_at)
            VALUES (?, ?, ?, ?)
        """, (data_type, content, now, now))
        
        record_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return record_id
    
    def get_records(self, data_type: str = None, limit: int = 100):
        """ãƒ¬ã‚³ãƒ¼ãƒ‰å–å¾—"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if data_type:
            cursor.execute("""
                SELECT id, data_type, content, created_at, updated_at
                FROM api_data WHERE data_type = ?
                ORDER BY created_at DESC LIMIT ?
            """, (data_type, limit))
        else:
            cursor.execute("""
                SELECT id, data_type, content, created_at, updated_at
                FROM api_data ORDER BY created_at DESC LIMIT ?
            """, (limit,))
        
        records = cursor.fetchall()
        conn.close()
        
        return [
            {{
                'id': row[0], 'data_type': row[1], 'content': row[2],
                'created_at': row[3], 'updated_at': row[4]
            }}
            for row in records
        ]

service = APIService()

@app.route('/api/data', methods=['GET'])
def get_data():
    """ãƒ‡ãƒ¼ã‚¿å–å¾—API"""
    data_type = request.args.get('type')
    limit = int(request.args.get('limit', 100))
    
    records = service.get_records(data_type=data_type, limit=limit)
    return jsonify({{'success': True, 'data': records, 'count': len(records)}})

@app.route('/api/data', methods=['POST'])
def create_data():
    """ãƒ‡ãƒ¼ã‚¿ä½œæˆAPI"""
    data = request.get_json()
    
    if not data or 'type' not in data or 'content' not in data:
        return jsonify({{'success': False, 'error': 'Invalid data format'}}), 400
    
    record_id = service.create_record(data['type'], data['content'])
    return jsonify({{'success': True, 'id': record_id}})

@app.route('/api/health', methods=['GET'])
def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯API"""
    return jsonify({{'status': 'healthy', 'timestamp': datetime.now().isoformat()}})

if __name__ == '__main__':
    app.run(debug=True, port=5000)
'''
            
            src_dir = workspace_dir / 'src'
            src_dir.mkdir(exist_ok=True)
            api_file = src_dir / 'api_server.py'
            with open(api_file, 'w', encoding='utf-8') as f:
                f.write(api_code)
            files.append(str(api_file))
            
            # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            (workspace_dir / 'data').mkdir(exist_ok=True)
            
            return files

        async def generate_dashboard_system(workspace_dir: Path, task, requirements: list) -> list:
            """ç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ç”Ÿæˆ"""
            files = []
            
            dashboard_code = f'''#!/usr/bin/env python3
"""
ç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ 
Generated by Nocturnal Agent with GitHub Spec Kit
Task: {task.description}
Generated at: {datetime.now().isoformat()}
"""

from flask import Flask, render_template, request, jsonify
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path

app = Flask(__name__)

class DashboardService:
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self, db_path: str = "data/dashboard_data.db"):
        self.db_path = db_path
        self.setup_database()
    
    def setup_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        Path(self.db_path).parent.mkdir(exist_ok=True)
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                metric_name TEXT,
                metric_value REAL,
                recorded_at TEXT
            )
        """)
        
        conn.commit()
        conn.close()
    
    def get_dashboard_stats(self):
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰çµ±è¨ˆå–å¾—"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åŸºæœ¬çµ±è¨ˆ
        cursor.execute("SELECT COUNT(*) FROM metrics")
        total_metrics = cursor.fetchone()[0]
        
        # æœ€æ–°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        cursor.execute("""
            SELECT metric_name, metric_value, recorded_at
            FROM metrics ORDER BY recorded_at DESC LIMIT 10
        """)
        latest_metrics = cursor.fetchall()
        
        conn.close()
        
        return {{
            'total_metrics': total_metrics,
            'latest_metrics': latest_metrics,
            'last_updated': datetime.now().isoformat()
        }}

service = DashboardService()

@app.route('/')
def dashboard():
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”»é¢"""
    stats = service.get_dashboard_stats()
    return render_template('dashboard.html', stats=stats)

@app.route('/api/stats')
def api_stats():
    """çµ±è¨ˆAPI"""
    stats = service.get_dashboard_stats()
    return jsonify(stats)

if __name__ == '__main__':
    app.run(debug=True, port=5000)
'''
            
            src_dir = workspace_dir / 'src'
            src_dir.mkdir(exist_ok=True)
            dashboard_file = src_dir / 'dashboard.py'
            with open(dashboard_file, 'w', encoding='utf-8') as f:
                f.write(dashboard_code)
            files.append(str(dashboard_file))
            
            return files

        async def generate_cli_tool(workspace_dir: Path, task, requirements: list) -> list:
            """CLIãƒ„ãƒ¼ãƒ«ç”Ÿæˆ"""
            files = []
            
            cli_code = f'''#!/usr/bin/env python3
"""
CLIãƒ„ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ 
Generated by Nocturnal Agent with GitHub Spec Kit
Task: {task.description}
Generated at: {datetime.now().isoformat()}
"""

import argparse
import sys
import json
from datetime import datetime
from pathlib import Path

class CLITool:
    """CLIãƒ„ãƒ¼ãƒ«åŸºç›¤"""
    
    def __init__(self):
        self.config_file = Path("config/cli_config.json")
        self.load_config()
    
    def load_config(self):
        """è¨­å®šèª­ã¿è¾¼ã¿"""
        if self.config_file.exists():
            with open(self.config_file, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
        else:
            self.config = {{"default_setting": "value"}}
            self.save_config()
    
    def save_config(self):
        """è¨­å®šä¿å­˜"""
        self.config_file.parent.mkdir(exist_ok=True)
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
    
    def execute_command(self, command: str, args: list):
        """ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ"""
        print(f"ğŸ”§ å®Ÿè¡Œä¸­: {{command}}")
        print(f"ğŸ“‹ å¼•æ•°: {{args}}")
        
        if command == "status":
            print("âœ… ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒä¸­")
        elif command == "process":
            print(f"ğŸ“Š å‡¦ç†å®Œäº†: {{len(args)}}é …ç›®")
        else:
            print(f"âŒ ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {{command}}")
        
        return True

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="Nocturnal Agent Generated CLI Tool",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('command', help='å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰')
    parser.add_argument('args', nargs='*', help='ã‚³ãƒãƒ³ãƒ‰å¼•æ•°')
    parser.add_argument('--config', help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    
    args = parser.parse_args()
    
    try:
        tool = CLITool()
        result = tool.execute_command(args.command, args.args)
        
        if result:
            print("ğŸ‰ å‡¦ç†å®Œäº†")
            sys.exit(0)
        else:
            print("ğŸ’¥ å‡¦ç†å¤±æ•—")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\\nâš ï¸ å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {{e}}")
        sys.exit(1)

if __name__ == "__main__":
    main()
'''
            
            src_dir = workspace_dir / 'src'
            src_dir.mkdir(exist_ok=True)
            cli_file = src_dir / 'cli_tool.py'
            with open(cli_file, 'w', encoding='utf-8') as f:
                f.write(cli_code)
            files.append(str(cli_file))
            
            return files

        async def generate_generic_system(workspace_dir: Path, task, requirements: list) -> list:
            """æ±ç”¨ã‚·ã‚¹ãƒ†ãƒ ç”Ÿæˆï¼ˆå¾“æ¥ã®å®Ÿè£…ï¼‰"""
            files = []
            
            generic_code = f'''#!/usr/bin/env python3
"""
{task.description}
Generated by Nocturnal Agent with GitHub Spec Kit
Generated at: {datetime.now().isoformat()}
"""

import asyncio
import logging
from datetime import datetime
from pathlib import Path

class GeneratedSystem:
    """
    Nocturnal Agentã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ 
    è¦ä»¶: {", ".join(requirements) if requirements else "æ±ç”¨å®Ÿè£…"}
    """
    
    def __init__(self):
        self.logger = self._setup_logging()
        self.created_at = datetime.now()
        
    def _setup_logging(self):
        """ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)
    
    async def run(self):
        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
        self.logger.info("ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
        
        # è¦ä»¶ã«åŸºã¥ãå®Ÿè£…
        try:
            await self._implement_requirements()
            self.logger.info("ã‚·ã‚¹ãƒ†ãƒ æ­£å¸¸çµ‚äº†")
        except Exception as e:
            self.logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {{e}}")
            raise
    
    async def _implement_requirements(self):
        """è¦ä»¶ã®å®Ÿè£…"""
        requirements_list = {requirements if requirements else ["æ±ç”¨æ©Ÿèƒ½å®Ÿè£…"]}
        for requirement in requirements_list:
            self.logger.info(f"å®Ÿè£…ä¸­: {{requirement}}")
            await asyncio.sleep(0.1)  # å‡¦ç†æ™‚é–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            self.logger.info(f"å®Œäº†: {{requirement}}")

async def main():
    """ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    system = GeneratedSystem()
    await system.run()

if __name__ == "__main__":
    asyncio.run(main())
'''
            
            output_file = workspace_dir / 'nocturnal_output' / f'generated_{task.id[:8]}.py'
            output_file.parent.mkdir(exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(generic_code)
            files.append(str(output_file))
            
            # READMEä½œæˆ
            readme_content = f'''# {task.description}

Generated by Nocturnal Agent at {datetime.now().isoformat()}

## Requirements Implemented

{chr(10).join(f"- {req}" for req in requirements) if requirements else "- æ±ç”¨ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…"}

## Usage

```bash
python {output_file.name}
```

## Features

- GitHub Spec Kit standards compliance
- Comprehensive error handling
- Structured logging system
- Asynchronous execution support

Generated with Nocturnal Agent's autonomous development system.
'''
            
            readme_file = workspace_dir / 'nocturnal_output' / f'README_{task.id[:8]}.md'
            with open(readme_file, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            files.append(str(readme_file))
            
            return files
        
        # Spec Kité§†å‹•å®Ÿè¡Œï¼ˆå¯¾è©±ãƒ­ã‚°ä»˜ãï¼‰
        print(f'\\nğŸš€ Spec Kité§†å‹•å®Ÿè¡Œé–‹å§‹...')
        result = await agent.execute_task_with_spec_design(
            task, 
            practical_executor, 
            SpecType.FEATURE
        )
        
        print(f'\\nğŸ‰ å®Ÿè¡Œå®Œäº†!')
        print(f'âœ… æˆåŠŸ: {result.success}')
        print(f'ğŸ“Š å“è³ªã‚¹ã‚³ã‚¢: {result.quality_score.overall:.2f}')
        print(f'â±ï¸ å®Ÿè¡Œæ™‚é–“: {result.execution_time}ç§’')
        
        if hasattr(result, 'files_created') and result.files_created:
            print(f'\\nğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:')
            for file_path in result.files_created:
                print(f'  âœ… {file_path}')
        
        # å¯¾è©±ãƒ­ã‚°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print(f'\\nğŸ“‹ å¯¾è©±ãƒ­ã‚°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...')
        report_file = agent.interaction_logger.export_interactions(session_id)
        print(f'ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}')
        
        return True
        
    except Exception as e:
        print(f'âŒ ã‚¨ãƒ©ãƒ¼: {e}')
        import traceback
        traceback.print_exc()
        return False

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # ã‚«ã‚¹ã‚¿ãƒ ã‚¿ã‚¹ã‚¯ã®ä¾‹
    task_desc = "Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®ä½œæˆ"
    requirements = [
        "Beautiful Soupã¨Requestsã‚’ä½¿ç”¨ã—ãŸã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°",
        "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœã®CSVå‡ºåŠ›",
        "ç‡åˆ¶é™ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°",
        "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ˆã‚‹ã‚¿ãƒ¼ã‚²ãƒƒãƒˆURLç®¡ç†",
        "ãƒ­ã‚°æ©Ÿèƒ½ã«ã‚ˆã‚‹å®Ÿè¡ŒçŠ¶æ³è¿½è·¡"
    ]
    
    success = asyncio.run(run_nocturnal_task(task_desc, requirements))
    
    if success:
        print(f'\\nğŸŒŸ Nocturnal Agent ã‚¿ã‚¹ã‚¯å®Ÿè¡ŒæˆåŠŸ!')
        print(f'ğŸ¯ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ ./nocturnal_output/ ã§ç¢ºèªã—ã¦ãã ã•ã„')
    else:
        print(f'\\nğŸ’¥ ã‚¿ã‚¹ã‚¯å®Ÿè¡Œå¤±æ•—')