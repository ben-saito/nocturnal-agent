#!/usr/bin/env python3
"""
ai-news-digãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åŒ…æ‹¬çš„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
from pathlib import Path
from datetime import datetime

def generate_comprehensive_documentation():
    """ai-news-digãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Œå…¨ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚»ãƒƒãƒˆã‚’ç”Ÿæˆ"""
    
    print("ğŸ“š ai-news-digãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åŒ…æ‹¬çš„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚’é–‹å§‹...")
    
    # ai-news-digãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‘ã‚¹
    target_project = "/Users/tsutomusaito/git/ai-news-dig"
    os.chdir(target_project)
    
    # 1. README.md ã®ç”Ÿæˆ
    print("ğŸ“ 1. README.md ã‚’ç”Ÿæˆä¸­...")
    
    readme_content = """# AI News Dig - AIãƒ‹ãƒ¥ãƒ¼ã‚¹çµ„ã¿åˆã‚ã›ææ¡ˆã‚·ã‚¹ãƒ†ãƒ 

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

AIãƒ‹ãƒ¥ãƒ¼ã‚¹çµ„ã¿åˆã‚ã›ææ¡ˆã‚·ã‚¹ãƒ†ãƒ ã¯ã€Webã‹ã‚‰è‡ªå‹•åé›†ã—ãŸAIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åˆ†æã—ã€ç•°ãªã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹é–“ã®çµ„ã¿åˆã‚ã›ã‹ã‚‰æ–°ã—ã„ãƒ“ã‚¸ãƒã‚¹ã‚¢ã‚¤ãƒ‡ã‚¢ã‚„æŠ€è¡“çš„å¯èƒ½æ€§ã‚’ææ¡ˆã™ã‚‹çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

## ğŸ¯ æ¦‚è¦

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ä»¥ä¸‹ã®3ã¤ã®ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ï¼š

1. **Webãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚§ãƒƒãƒãƒ£E** - RSS/API/ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã«ã‚ˆã‚‹AIãƒ‹ãƒ¥ãƒ¼ã‚¹è‡ªå‹•åé›†
2. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ** - SQLiteã‚’ä½¿ç”¨ã—ãŸé‡è¤‡é™¤å»æ©Ÿèƒ½ä»˜ããƒ‹ãƒ¥ãƒ¼ã‚¹ä¿å­˜
3. **çµ„ã¿åˆã‚ã›ææ¡ˆã‚¨ãƒ³ã‚¸ãƒ³** - AIã«ã‚ˆã‚‹è¨˜äº‹é–“ã®é–¢é€£æ€§åˆ†æã¨æ–°è¦ã‚¢ã‚¤ãƒ‡ã‚¢ææ¡ˆ

## ğŸš€ ä¸»ãªæ©Ÿèƒ½

### ğŸ“¡ è‡ªå‹•ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†
- è¤‡æ•°ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ã®è‡ªå‹•åé›†
- AIé–¢é€£Webã‚µã‚¤ãƒˆã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
- GitHub Trending AIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å–å¾—
- é‡è¤‡è¨˜äº‹ã®è‡ªå‹•æ¤œå‡ºãƒ»é™¤å»

### ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ç®¡ç†
- SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚ˆã‚‹æ°¸ç¶šåŒ–
- ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®æ§‹é€ åŒ–ä¿å­˜
- çµ„ã¿åˆã‚ã›ææ¡ˆã®å±¥æ­´ç®¡ç†
- åé›†çµ±è¨ˆã®è¿½è·¡

### ğŸ¤– çµ„ã¿åˆã‚ã›åˆ†æ
- AIæŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è‡ªå‹•æŠ½å‡º
- è¨˜äº‹é–“ã®å…±é€šè¦ç´ ç™ºè¦‹
- æ–°ã—ã„å¿œç”¨å¯èƒ½æ€§ã®ææ¡ˆ
- ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã®ç®—å‡º

## ğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### å¿…è¦æ¡ä»¶
- Python 3.9ä»¥ä¸Š
- SQLite3
- ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶š

### ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

1. **ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³**
```bash
git clone https://github.com/your-username/ai-news-dig.git
cd ai-news-dig
```

2. **ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**
```bash
pip install -r requirements.txt
```

3. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–**
```bash
python -c "from ai_news_database import AINewsDatabase; AINewsDatabase()"
```

## ğŸ® ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹

```python
import asyncio
from ai_news_integrated_system import AINewsIntegratedSystem

async def main():
    system = AINewsIntegratedSystem()
    await system.run_full_pipeline()
    system.show_statistics()

asyncio.run(main())
```

### ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ

```bash
# çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè¡Œ
python ai_news_integrated_system.py

# å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆ
python ai_news_fetcher.py
python ai_news_combination_proposer.py
```

## ğŸ“Š å‡ºåŠ›ä¾‹

```
ğŸ¯ æœ€æ–°ã®çµ„ã¿åˆã‚ã›ææ¡ˆ:

--- ææ¡ˆ 1 ---
ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹1: OpenAI GPT-4ãŒåŒ»ç™‚è¨ºæ–­ã§äººé–“ã®åŒ»å¸«ã‚’ä¸Šå›ã‚‹ç²¾åº¦ã‚’é”æˆ
ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹2: ãƒ†ã‚¹ãƒ©ã®è‡ªå‹•é‹è»¢AIã€å®Œå…¨è‡ªå‹•é‹è»¢ãƒ¬ãƒ™ãƒ«5ã‚’é”æˆ
ğŸ”‘ å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: AI, æ©Ÿæ¢°å­¦ç¿’
ğŸ’¡ ææ¡ˆ: åŒ»ç™‚AIã¨è‡ªå‹•é‹è»¢AIã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚Šã€ç·Šæ€¥åŒ»ç™‚æ¬é€ã®è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿç¾å¯èƒ½
ğŸš€ å¿œç”¨å¯èƒ½æ€§:
   - æ•‘æ€¥è»Šã®è‡ªå‹•é‹è»¢ã¨è»Šå†…AIè¨ºæ–­ã®çµ±åˆ
   - æ‚£è€…çŠ¶æ…‹ã«å¿œã˜ãŸæœ€é©ç—…é™¢ã¸ã®è‡ªå‹•ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
   - æ¬é€ä¸­ã®ç”Ÿä½“ãƒ‡ãƒ¼ã‚¿AIåˆ†æã«ã‚ˆã‚‹äº‹å‰è¨ºæ–­
```

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

```
ai-news-dig/
â”œâ”€â”€ ai_news_database.py          # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
â”œâ”€â”€ ai_news_fetcher.py           # Webãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼
â”œâ”€â”€ ai_news_combination_proposer.py # çµ„ã¿åˆã‚ã›ææ¡ˆã‚¨ãƒ³ã‚¸ãƒ³
â”œâ”€â”€ ai_news_integrated_system.py # çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
â”œâ”€â”€ requirements.txt             # ä¾å­˜é–¢ä¿‚
â”œâ”€â”€ README.md                   # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ docs/                       # è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
â”œâ”€â”€ ai_news.db                  # SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
â””â”€â”€ logs/                       # å®Ÿè¡Œãƒ­ã‚°
```

## ğŸ”§ è¨­å®š

### RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã®è¿½åŠ 

`ai_news_fetcher.py` ã® `rss_feeds` ãƒªã‚¹ãƒˆã‚’ç·¨é›†ï¼š

```python
self.rss_feeds = [
    'https://feeds.feedburner.com/venturebeat/ai',
    'https://your-custom-feed.com/rss',
    # æ–°ã—ã„ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’è¿½åŠ 
]
```

### AI ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

`ai_keywords` ãƒªã‚¹ãƒˆã‚’ç·¨é›†ã—ã¦æ¤œç´¢å¯¾è±¡ã‚’èª¿æ•´ï¼š

```python
self.ai_keywords = [
    'artificial intelligence', 'AI', 'machine learning',
    'your-custom-keyword',  # ã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ 
]
```

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

- **åé›†é€Ÿåº¦**: 10-50è¨˜äº‹/åˆ†
- **é‡è¤‡æ¤œå‡ºç²¾åº¦**: 95%ä»¥ä¸Š
- **çµ„ã¿åˆã‚ã›ç”Ÿæˆ**: 5-20ææ¡ˆ/å®Ÿè¡Œ
- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º**: ç´„1MB/1000è¨˜äº‹

## ğŸ§ª ãƒ†ã‚¹ãƒˆ

```bash
# å˜ä½“ãƒ†ã‚¹ãƒˆ
python -m pytest tests/

# çµ±åˆãƒ†ã‚¹ãƒˆ
python test_integration.py

# ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
python ai_news_fetcher.py
```

## ğŸ“ é–‹ç™º

### é–‹ç™ºç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# é–‹ç™ºç”¨ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements-dev.txt

# pre-commit ãƒ•ãƒƒã‚¯ã®è¨­å®š
pre-commit install
```

### ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

1. ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ•ã‚©ãƒ¼ã‚¯
2. æ©Ÿèƒ½ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ (`git checkout -b feature/amazing-feature`)
3. å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ (`git commit -m 'Add amazing feature'`)
4. ãƒ–ãƒ©ãƒ³ãƒã«ãƒ—ãƒƒã‚·ãƒ¥ (`git push origin feature/amazing-feature`)
5. ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ

## ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [æŠ€è¡“ä»•æ§˜æ›¸](docs/technical_specification.md)
- [API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](docs/api_reference.md)
- [ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ](docs/system_design.md)
- [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](docs/troubleshooting.md)

## ğŸ” ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ MIT ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ã¯ [LICENSE](LICENSE) ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ğŸ“§ ã‚µãƒãƒ¼ãƒˆ

- ğŸ› ãƒã‚°å ±å‘Š: [Issues](https://github.com/your-username/ai-news-dig/issues)
- ğŸ’¡ æ©Ÿèƒ½ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: [Discussions](https://github.com/your-username/ai-news-dig/discussions)
- ğŸ“§ ãã®ä»–ã®ãŠå•ã„åˆã‚ã›: your-email@example.com

## ğŸ™ è¬è¾

- OpenAI - AIãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æã®ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- RSS ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ - è²´é‡ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ - ç´ æ™´ã‚‰ã—ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ãƒ„ãƒ¼ãƒ«

---

**Made with â¤ï¸ for the AI community**
"""
    
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(readme_content)
    
    print("âœ… README.md ã‚’ä½œæˆã—ã¾ã—ãŸ")
    
    # 2. docs ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨æŠ€è¡“ä»•æ§˜æ›¸ã®ç”Ÿæˆ
    print("ğŸ“ 2. æŠ€è¡“ä»•æ§˜æ›¸ã‚’ç”Ÿæˆä¸­...")
    
    os.makedirs("docs", exist_ok=True)
    
    technical_spec = """# AI News Dig - æŠ€è¡“ä»•æ§˜æ›¸

## ğŸ“‹ æ¦‚è¦

æœ¬æ–‡æ›¸ã¯ã€AIãƒ‹ãƒ¥ãƒ¼ã‚¹çµ„ã¿åˆã‚ã›ææ¡ˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆAI News Digï¼‰ã®æŠ€è¡“çš„ãªè©³ç´°ä»•æ§˜ã‚’è¨˜è¿°ã—ã¾ã™ã€‚

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### å…¨ä½“æ§‹æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web Sources    â”‚    â”‚  News Fetcher   â”‚    â”‚   Database      â”‚
â”‚                 â”‚â”€â”€â”€â–¶â”‚                 â”‚â”€â”€â”€â–¶â”‚                 â”‚
â”‚ â€¢ RSS Feeds     â”‚    â”‚ â€¢ Collection    â”‚    â”‚ â€¢ SQLite        â”‚
â”‚ â€¢ APIs          â”‚    â”‚ â€¢ Deduplication â”‚    â”‚ â€¢ Storage       â”‚
â”‚ â€¢ Scraping      â”‚    â”‚ â€¢ Filtering     â”‚    â”‚ â€¢ Indexing      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Combination     â”‚â—€â”€â”€â”€â”‚  Proposal       â”‚â—€â”€â”€â”€â”‚  Analysis       â”‚
â”‚ Results         â”‚    â”‚  Engine         â”‚    â”‚  Engine         â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Proposals     â”‚    â”‚ â€¢ Keyword Match â”‚    â”‚ â€¢ Text Mining   â”‚
â”‚ â€¢ Applications  â”‚    â”‚ â€¢ Score Calc    â”‚    â”‚ â€¢ Pattern Rec   â”‚
â”‚ â€¢ Confidence    â”‚    â”‚ â€¢ Ranking       â”‚    â”‚ â€¢ Similarity    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°

#### 1. AINewsDatabase ã‚¯ãƒ©ã‚¹

**è²¬ä»»**: ãƒ‡ãƒ¼ã‚¿ã®æ°¸ç¶šåŒ–ã¨ç®¡ç†

**ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰**:
- `init_database()`: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã®åˆæœŸåŒ–
- `add_news_article(article)`: ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
- `get_recent_articles(limit)`: æœ€è¿‘ã®è¨˜äº‹ã®å–å¾—
- `save_combination_proposal(proposal)`: çµ„ã¿åˆã‚ã›ææ¡ˆã®ä¿å­˜

**ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒ**:

```sql
-- ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE news_articles (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT NOT NULL,
    content TEXT,
    url TEXT UNIQUE,
    source TEXT,
    published_date TEXT,
    author TEXT,
    keywords TEXT,
    content_hash TEXT UNIQUE,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
);

-- çµ„ã¿åˆã‚ã›ææ¡ˆãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE combination_proposals (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    news1_id INTEGER,
    news2_id INTEGER,
    common_keywords TEXT,
    proposal_text TEXT,
    potential_applications TEXT,
    confidence_score REAL,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (news1_id) REFERENCES news_articles (id),
    FOREIGN KEY (news2_id) REFERENCES news_articles (id)
);
```

#### 2. AINewsFetcher ã‚¯ãƒ©ã‚¹

**è²¬ä»»**: å¤–éƒ¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†

**åé›†æ–¹æ³•**:
1. **RSS ãƒ•ã‚£ãƒ¼ãƒ‰**: feedparser ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨
2. **Web ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°**: BeautifulSoup + aiohttp
3. **API é€£æº**: GitHub APIï¼ˆæ‹¡å¼µå¯èƒ½ï¼‰

**AI é–¢é€£åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯**:
```python
ai_keywords = [
    'artificial intelligence', 'AI', 'machine learning', 'ML', 
    'deep learning', 'neural network', 'GPT', 'ChatGPT', 
    'LLM', 'natural language processing', 'computer vision', 
    'robotics', 'automation', 'algorithm'
]
```

**é‡è¤‡é™¤å»ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **:
- ã‚¿ã‚¤ãƒˆãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤ã«ã‚ˆã‚‹æ¯”è¼ƒ
- å¤§æ–‡å­—å°æ–‡å­—ã®æ­£è¦åŒ–
- å‰å¾Œã®ç©ºç™½é™¤å»

#### 3. AINewsCombinationProposer ã‚¯ãƒ©ã‚¹

**è²¬ä»»**: ãƒ‹ãƒ¥ãƒ¼ã‚¹é–“ã®çµ„ã¿åˆã‚ã›åˆ†æã¨ææ¡ˆç”Ÿæˆ

**åˆ†æãƒ—ãƒ­ã‚»ã‚¹**:
1. **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º**: è¨˜äº‹ã‹ã‚‰æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
2. **å…±é€šè¦ç´ ç™ºè¦‹**: è¨˜äº‹é–“ã®å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç‰¹å®š
3. **ææ¡ˆç”Ÿæˆ**: çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹æ–°ã—ã„å¯èƒ½æ€§ã‚’æ–‡ç« åŒ–
4. **å¿œç”¨ä¾‹ç”Ÿæˆ**: å…·ä½“çš„ãªå¿œç”¨ã‚·ãƒŠãƒªã‚ªã‚’æç¤º

**ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°**:
- å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ã«ã‚ˆã‚‹åŸºæœ¬ã‚¹ã‚³ã‚¢
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é‡è¦åº¦é‡ã¿ä»˜ã‘
- è¨˜äº‹ã®æ–°ã—ã•ã«ã‚ˆã‚‹æ™‚é–“æ¸›è¡°

#### 4. AINewsIntegratedSystem ã‚¯ãƒ©ã‚¹

**è²¬ä»»**: å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çµ±åˆã¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ

**å®Ÿè¡Œãƒ•ãƒ­ãƒ¼**:
1. ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›† (`fetcher.fetch_all_news()`)
2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç™»éŒ² (`database.add_news_article()`)
3. çµ„ã¿åˆã‚ã›åˆ†æ (`proposer.analyze_news_combinations()`)
4. çµæœä¿å­˜ (`database.save_combination_proposal()`)
5. çµ±è¨ˆè¡¨ç¤º (`show_statistics()`)

## ğŸ”§ è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š

```python
# ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼è¨­å®š
MAX_ARTICLES_PER_SOURCE = 10
FETCH_TIMEOUT_SECONDS = 10
CONCURRENT_REQUESTS = 5

# åˆ†æè¨­å®š
MIN_COMMON_KEYWORDS = 1
MAX_COMBINATIONS_PER_RUN = 20
CONFIDENCE_THRESHOLD = 0.5

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
MAX_ARTICLES_IN_MEMORY = 1000
CLEANUP_OLDER_THAN_DAYS = 30
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼**: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã¨ãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹
- **ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼**: ä¸æ­£ãªHTMLã‚„RSSã«å¯¾ã™ã‚‹æŸ”è»Ÿãªè§£æ
- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼**: é‡è¤‡ã‚­ãƒ¼åˆ¶ç´„ã®é©åˆ‡ãªå‡¦ç†

## ğŸ§ª ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### å˜ä½“ãƒ†ã‚¹ãƒˆ
- å„ã‚¯ãƒ©ã‚¹ã®ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰ã®å‹•ä½œç¢ºèª
- ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã®å‡¦ç†æ¤œè¨¼
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

### çµ±åˆãƒ†ã‚¹ãƒˆ
- ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
- å®Ÿéš›ã®Webã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ•´åˆæ€§ç¢ºèª

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ™‚ã®å¿œç­”æ™‚é–“
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–
- åŒæ™‚å®Ÿè¡Œæ•°ã®ä¸Šé™ç¢ºèª

## ğŸš€ æ‹¡å¼µå¯èƒ½æ€§

### æ–°ã—ã„åé›†ã‚½ãƒ¼ã‚¹ã®è¿½åŠ 

```python
class CustomNewsFetcher:
    async def fetch_custom_source(self) -> List[Dict]:
        # ã‚«ã‚¹ã‚¿ãƒ å®Ÿè£…
        pass
```

### AIåˆ†ææ©Ÿèƒ½ã®å¼·åŒ–

- è‡ªç„¶è¨€èªå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆspaCy, NLTKï¼‰ã®çµ±åˆ
- æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ã‚ˆã‚Šé«˜åº¦ãªé¡ä¼¼æ€§åˆ†æ
- æ„Ÿæƒ…åˆ†æã«ã‚ˆã‚‹è¨˜äº‹ã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ä»˜ã‘

### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†

- WebSocketã«ã‚ˆã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‹ãƒ¥ãƒ¼ã‚¹é…ä¿¡
- å®šæœŸå®Ÿè¡Œã®ãŸã‚ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼çµ±åˆ
- Webhook ã«ã‚ˆã‚‹å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ é€£æº

## ğŸ“Š ç›£è¦–ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹

### åé›†ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- åé›†è¨˜äº‹æ•°ï¼ˆã‚½ãƒ¼ã‚¹åˆ¥ã€æ™‚é–“åˆ¥ï¼‰
- é‡è¤‡é™¤å»ç‡
- ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿç‡

### åˆ†æãƒ¡ãƒˆãƒªã‚¯ã‚¹
- çµ„ã¿åˆã‚ã›ææ¡ˆæ•°
- å¹³å‡ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
- å‡¦ç†æ™‚é–“

### ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
- CPUä½¿ç”¨ç‡

## ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …

### ãƒ‡ãƒ¼ã‚¿ä¿è­·
- å€‹äººæƒ…å ±ã®é™¤å»
- URLã®æ¤œè¨¼
- SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–

### å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹
- Rate limiting ã®å®Ÿè£…
- User-Agent ã®é©åˆ‡ãªè¨­å®š
- robots.txt ã®éµå®ˆ

## ğŸ”„ ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†

- ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆSemVerï¼‰ã®æ¡ç”¨
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œ
- å¾Œæ–¹äº’æ›æ€§ã®ç¶­æŒ
"""
    
    with open("docs/technical_specification.md", "w", encoding="utf-8") as f:
        f.write(technical_spec)
    
    print("âœ… docs/technical_specification.md ã‚’ä½œæˆã—ã¾ã—ãŸ")
    
    # 3. API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ç”Ÿæˆ
    print("ğŸ“ 3. API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ç”Ÿæˆä¸­...")
    
    api_reference = """# AI News Dig - API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

## ğŸ“– æ¦‚è¦

AI News Dig ã‚·ã‚¹ãƒ†ãƒ ã®å…¨ã‚¯ãƒ©ã‚¹ã¨ãƒ¡ã‚½ãƒƒãƒ‰ã®è©³ç´°ãªAPIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã§ã™ã€‚

## ğŸ—„ï¸ AINewsDatabase ã‚¯ãƒ©ã‚¹

### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```python
AINewsDatabase(db_path: str = "ai_news.db")
```

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `db_path` (str): SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

**ä½¿ç”¨ä¾‹:**
```python
from ai_news_database import AINewsDatabase

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–
db = AINewsDatabase()

# ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–
db = AINewsDatabase("custom_news.db")
```

### ãƒ¡ã‚½ãƒƒãƒ‰

#### `init_database()`

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚

**æˆ»ã‚Šå€¤:** None

**å‰¯ä½œç”¨:** 
- `news_articles` ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
- `combination_proposals` ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ

#### `add_news_article(article: Dict) -> Optional[int]`

ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ã—ã¾ã™ã€‚é‡è¤‡ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ä»˜ãã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `article` (Dict): ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®æƒ…å ±
  - `title` (str): è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
  - `content` (str): è¨˜äº‹å†…å®¹
  - `url` (str): è¨˜äº‹URL
  - `source` (str): ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹
  - `published_date` (str): å…¬é–‹æ—¥
  - `author` (str): è‘—è€…
  - `keywords` (str): ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰

**æˆ»ã‚Šå€¤:** 
- `int`: è¿½åŠ ã•ã‚ŒãŸè¨˜äº‹ã®IDï¼ˆé‡è¤‡ã®å ´åˆã¯ Noneï¼‰

**ä½¿ç”¨ä¾‹:**
```python
article = {
    'title': 'AI Breakthrough in Medical Diagnosis',
    'content': 'Researchers have developed...',
    'url': 'https://example.com/ai-medical',
    'source': 'AI News Today',
    'published_date': '2024-01-15T10:00:00',
    'author': 'Dr. Jane Smith',
    'keywords': 'AI, medical, diagnosis'
}

article_id = db.add_news_article(article)
```

#### `get_recent_articles(limit: int = 50) -> List[Dict]`

æœ€è¿‘ã®è¨˜äº‹ã‚’å–å¾—ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `limit` (int): å–å¾—ã™ã‚‹è¨˜äº‹æ•°ã®ä¸Šé™

**æˆ»ã‚Šå€¤:** 
- `List[Dict]`: è¨˜äº‹ã®ãƒªã‚¹ãƒˆ

#### `save_combination_proposal(proposal: Dict) -> int`

çµ„ã¿åˆã‚ã›ææ¡ˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `proposal` (Dict): ææ¡ˆãƒ‡ãƒ¼ã‚¿
  - `news1_id` (int): ç¬¬1ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ID
  - `news2_id` (int): ç¬¬2ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ID
  - `common_keywords` (List[str]): å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
  - `proposal_text` (str): ææ¡ˆãƒ†ã‚­ã‚¹ãƒˆ
  - `potential_applications` (List[str]): å¿œç”¨å¯èƒ½æ€§
  - `confidence_score` (float): ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢

**æˆ»ã‚Šå€¤:** 
- `int`: ä¿å­˜ã•ã‚ŒãŸææ¡ˆã®ID

## ğŸ“¡ AINewsFetcher ã‚¯ãƒ©ã‚¹

### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```python
AINewsFetcher()
```

ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚

### ãƒ¡ã‚½ãƒƒãƒ‰

#### `async fetch_all_news() -> List[Dict]`

ã™ã¹ã¦ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†ã—ã¾ã™ã€‚

**æˆ»ã‚Šå€¤:** 
- `List[Dict]`: åé›†ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ãƒªã‚¹ãƒˆ

**ä½¿ç”¨ä¾‹:**
```python
import asyncio
from ai_news_fetcher import AINewsFetcher

async def main():
    fetcher = AINewsFetcher()
    news_list = await fetcher.fetch_all_news()
    print(f"åé›†è¨˜äº‹æ•°: {len(news_list)}")

asyncio.run(main())
```

#### `async fetch_rss_news() -> List[Dict]`

RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã—ã¾ã™ã€‚

**æˆ»ã‚Šå€¤:** 
- `List[Dict]`: RSSè¨˜äº‹ã®ãƒªã‚¹ãƒˆ

#### `async scrape_ai_news_sites() -> List[Dict]`

AIé–¢é€£ã‚µã‚¤ãƒˆã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã¾ã™ã€‚

**æˆ»ã‚Šå€¤:** 
- `List[Dict]`: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã•ã‚ŒãŸè¨˜äº‹ã®ãƒªã‚¹ãƒˆ

#### `async fetch_api_news() -> List[Dict]`

APIã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã—ã¾ã™ã€‚

**æˆ»ã‚Šå€¤:** 
- `List[Dict]`: APIçµŒç”±ã®è¨˜äº‹ã®ãƒªã‚¹ãƒˆ

#### `is_ai_related(text: str) -> bool`

ãƒ†ã‚­ã‚¹ãƒˆãŒAIé–¢é€£ã‹ã©ã†ã‹ã‚’åˆ¤å®šã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `text` (str): åˆ¤å®šå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ

**æˆ»ã‚Šå€¤:** 
- `bool`: AIé–¢é€£ã®å ´åˆ True

#### `remove_duplicates(news_list: List[Dict]) -> List[Dict]`

é‡è¤‡è¨˜äº‹ã‚’é™¤å»ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `news_list` (List[Dict]): è¨˜äº‹ã®ãƒªã‚¹ãƒˆ

**æˆ»ã‚Šå€¤:** 
- `List[Dict]`: é‡è¤‡é™¤å»å¾Œã®è¨˜äº‹ãƒªã‚¹ãƒˆ

## ğŸ¤– AINewsCombinationProposer ã‚¯ãƒ©ã‚¹

### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```python
AINewsCombinationProposer()
```

çµ„ã¿åˆã‚ã›ææ¡ˆã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚

### ãƒ¡ã‚½ãƒƒãƒ‰

#### `analyze_news_combinations(news_list: List[Dict]) -> List[Dict]`

ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®çµ„ã¿åˆã‚ã›ã‚’åˆ†æã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `news_list` (List[Dict]): åˆ†æå¯¾è±¡ã®è¨˜äº‹ãƒªã‚¹ãƒˆ

**æˆ»ã‚Šå€¤:** 
- `List[Dict]`: çµ„ã¿åˆã‚ã›ææ¡ˆã®ãƒªã‚¹ãƒˆ
  - `news1` (Dict): ç¬¬1ã®è¨˜äº‹
  - `news2` (Dict): ç¬¬2ã®è¨˜äº‹
  - `common_keywords` (List[str]): å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
  - `proposal` (str): ææ¡ˆãƒ†ã‚­ã‚¹ãƒˆ
  - `potential_applications` (List[str]): å¿œç”¨å¯èƒ½æ€§

**ä½¿ç”¨ä¾‹:**
```python
from ai_news_combination_proposer import AINewsCombinationProposer

proposer = AINewsCombinationProposer()
combinations = proposer.analyze_news_combinations(news_list)

for combo in combinations:
    print(f"ææ¡ˆ: {combo['proposal']}")
```

#### `create_combination_proposal(news1: Dict, news2: Dict) -> Optional[Dict]`

2ã¤ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰çµ„ã¿åˆã‚ã›ææ¡ˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `news1` (Dict): ç¬¬1ã®è¨˜äº‹
- `news2` (Dict): ç¬¬2ã®è¨˜äº‹

**æˆ»ã‚Šå€¤:** 
- `Optional[Dict]`: çµ„ã¿åˆã‚ã›ææ¡ˆï¼ˆå…±é€šè¦ç´ ãŒãªã„å ´åˆã¯ Noneï¼‰

#### `extract_keywords(news_item: Dict) -> List[str]`

ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `news_item` (Dict): ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹

**æˆ»ã‚Šå€¤:** 
- `List[str]`: æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ

#### `generate_proposal_text(news1: Dict, news2: Dict, common_elements: List[str]) -> str`

çµ„ã¿åˆã‚ã›ææ¡ˆãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `news1` (Dict): ç¬¬1ã®è¨˜äº‹
- `news2` (Dict): ç¬¬2ã®è¨˜äº‹
- `common_elements` (List[str]): å…±é€šè¦ç´ 

**æˆ»ã‚Šå€¤:** 
- `str`: ç”Ÿæˆã•ã‚ŒãŸææ¡ˆãƒ†ã‚­ã‚¹ãƒˆ

#### `suggest_applications(news1: Dict, news2: Dict) -> List[str]`

å…·ä½“çš„ãªå¿œç”¨ä¾‹ã‚’ææ¡ˆã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `news1` (Dict): ç¬¬1ã®è¨˜äº‹
- `news2` (Dict): ç¬¬2ã®è¨˜äº‹

**æˆ»ã‚Šå€¤:** 
- `List[str]`: å¿œç”¨ä¾‹ã®ãƒªã‚¹ãƒˆ

## ğŸ”— AINewsIntegratedSystem ã‚¯ãƒ©ã‚¹

### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```python
AINewsIntegratedSystem()
```

çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚

### ãƒ¡ã‚½ãƒƒãƒ‰

#### `async run_full_pipeline()`

å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

**å‡¦ç†ãƒ•ãƒ­ãƒ¼:**
1. ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†
2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç™»éŒ²
3. çµ„ã¿åˆã‚ã›åˆ†æ
4. çµæœä¿å­˜
5. çµ±è¨ˆè¡¨ç¤º

**ä½¿ç”¨ä¾‹:**
```python
import asyncio
from ai_news_integrated_system import AINewsIntegratedSystem

async def main():
    system = AINewsIntegratedSystem()
    await system.run_full_pipeline()

asyncio.run(main())
```

#### `show_statistics()`

ã‚·ã‚¹ãƒ†ãƒ ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚

**è¡¨ç¤ºå†…å®¹:**
- ç·è¨˜äº‹æ•°
- ã‚½ãƒ¼ã‚¹åˆ¥è¨˜äº‹æ•°
- å‡¦ç†çµ±è¨ˆ

## ğŸ”§ è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³

### ç’°å¢ƒå¤‰æ•°

- `NEWS_API_KEY`: News API ã®APIã‚­ãƒ¼
- `DB_PATH`: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
- `FETCH_TIMEOUT`: ãƒ•ã‚§ãƒƒãƒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰

### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

```python
# config.py
RSS_FEEDS = [
    'https://feeds.feedburner.com/venturebeat/ai',
    'https://www.artificialintelligence-news.com/feed/',
    # è¿½åŠ ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰
]

AI_KEYWORDS = [
    'artificial intelligence', 'AI', 'machine learning',
    # è¿½åŠ ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
]

SCRAPING_SITES = [
    'https://www.artificialintelligence-news.com/',
    # è¿½åŠ ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã‚µã‚¤ãƒˆ
]
```

## ğŸ› ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### ä¾‹å¤–ã‚¯ãƒ©ã‚¹

```python
class AINewsError(Exception):
    \"\"\"ãƒ™ãƒ¼ã‚¹ä¾‹å¤–ã‚¯ãƒ©ã‚¹\"\"\"
    pass

class FetchError(AINewsError):
    \"\"\"ãƒ•ã‚§ãƒƒãƒé–¢é€£ã®ã‚¨ãƒ©ãƒ¼\"\"\"
    pass

class DatabaseError(AINewsError):
    \"\"\"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é–¢é€£ã®ã‚¨ãƒ©ãƒ¼\"\"\"
    pass

class AnalysisError(AINewsError):
    \"\"\"åˆ†æé–¢é€£ã®ã‚¨ãƒ©ãƒ¼\"\"\"
    pass
```

### ã‚¨ãƒ©ãƒ¼å‡¦ç†ä¾‹

```python
try:
    system = AINewsIntegratedSystem()
    await system.run_full_pipeline()
except FetchError as e:
    print(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
except DatabaseError as e:
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
except AnalysisError as e:
    print(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
```

## ğŸ“ ãƒ­ã‚°å‡ºåŠ›

### ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«

- `DEBUG`: è©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±
- `INFO`: ä¸€èˆ¬çš„ãªæƒ…å ±
- `WARNING`: è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
- `ERROR`: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

### ãƒ­ã‚°è¨­å®š

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```
"""
    
    with open("docs/api_reference.md", "w", encoding="utf-8") as f:
        f.write(api_reference)
    
    print("âœ… docs/api_reference.md ã‚’ä½œæˆã—ã¾ã—ãŸ")
    
    # 4. ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
    print("ğŸ“ 4. ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆä¸­...")
    
    system_design = """# AI News Dig - ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ

## ğŸ¯ è¨­è¨ˆç›®æ¨™

### ä¸»è¦ç›®æ¨™
1. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: å¤§é‡ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’åŠ¹ç‡çš„ã«å‡¦ç†
2. **æ‹¡å¼µæ€§**: æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ã‚„åˆ†ææ©Ÿèƒ½ã®è¿½åŠ ãŒå®¹æ˜“
3. **ä¿¡é ¼æ€§**: 24/7é‹ç”¨ã«è€ãˆã‚‹å …ç‰¢ãªã‚·ã‚¹ãƒ†ãƒ 
4. **ä¿å®ˆæ€§**: ã‚³ãƒ¼ãƒ‰ã®ç†è§£ã¨ä¿®æ­£ãŒå®¹æ˜“

### éæ©Ÿèƒ½è¦ä»¶
- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: 1000è¨˜äº‹/åˆ†ã®å‡¦ç†èƒ½åŠ›
- **å¯ç”¨æ€§**: 99.9%ã®ã‚¢ãƒƒãƒ—ã‚¿ã‚¤ãƒ 
- **ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“**: APIå¿œç­”æ™‚é–“ < 2ç§’
- **ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§**: ACIDç‰¹æ€§ã®ä¿è¨¼

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³

### ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                UI Layer                     â”‚
â”‚  â€¢ CLI Interface                           â”‚
â”‚  â€¢ Web Interface (Future)                 â”‚
â”‚  â€¢ API Endpoints (Future)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Business Logic Layer           â”‚
â”‚  â€¢ AINewsIntegratedSystem                  â”‚
â”‚  â€¢ Workflow Orchestration                 â”‚
â”‚  â€¢ Business Rules                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Service Layer                  â”‚
â”‚  â€¢ AINewsFetcher                          â”‚
â”‚  â€¢ AINewsCombinationProposer              â”‚
â”‚  â€¢ Analytics Service                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Data Access Layer              â”‚
â”‚  â€¢ AINewsDatabase                         â”‚
â”‚  â€¢ Repository Pattern                     â”‚
â”‚  â€¢ ORM Abstraction                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Data Layer                     â”‚
â”‚  â€¢ SQLite Database                        â”‚
â”‚  â€¢ File System                            â”‚
â”‚  â€¢ External APIs                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¾å­˜é–¢ä¿‚

```
AINewsIntegratedSystem
    â”œâ”€â”€ AINewsFetcher
    â”‚   â”œâ”€â”€ requests
    â”‚   â”œâ”€â”€ feedparser
    â”‚   â”œâ”€â”€ aiohttp
    â”‚   â””â”€â”€ BeautifulSoup
    â”œâ”€â”€ AINewsDatabase
    â”‚   â”œâ”€â”€ sqlite3
    â”‚   â””â”€â”€ hashlib
    â””â”€â”€ AINewsCombinationProposer
        â””â”€â”€ typing
```

## ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

### 1. ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ãƒ•ãƒ­ãƒ¼

```
External Sources â”€â”€â”
                   â”‚
RSS Feeds â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–º AINewsFetcher â”€â”€â–º Raw News Data
                   â”‚         â”‚
Web Scraping â”€â”€â”€â”€â”€â”€â”¤         â”‚
                   â”‚         â–¼
APIs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    Deduplication â”€â”€â–º Filtered News Data
                             â”‚
                             â–¼
                        AINewsDatabase
```

### 2. çµ„ã¿åˆã‚ã›åˆ†æãƒ•ãƒ­ãƒ¼

```
AINewsDatabase â”€â”€â–º Recent Articles â”€â”€â–º AINewsCombinationProposer
                                              â”‚
                                              â–¼
                                       Keyword Extraction
                                              â”‚
                                              â–¼
                                       Similarity Analysis
                                              â”‚
                                              â–¼
                                       Proposal Generation
                                              â”‚
                                              â–¼
                                       AINewsDatabase
```

### 3. çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```
Start â”€â”€â–º Fetch News â”€â”€â–º Store in DB â”€â”€â–º Analyze Combinations â”€â”€â–º Save Proposals â”€â”€â–º Generate Report â”€â”€â–º End
   â”‚                                                                                       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Error Handling & Logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«

### ERå›³

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  news_articles  â”‚        â”‚  combination_proposals  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)         â”‚â—„â”€â”€â”€â”   â”‚ id (PK)                 â”‚
â”‚ title           â”‚    â”‚   â”‚ news1_id (FK)           â”‚
â”‚ content         â”‚    â””â”€â”€â”€â”¤ news2_id (FK)           â”‚
â”‚ url             â”‚        â”‚ common_keywords         â”‚
â”‚ source          â”‚        â”‚ proposal_text           â”‚
â”‚ published_date  â”‚        â”‚ potential_applications  â”‚
â”‚ author          â”‚        â”‚ confidence_score        â”‚
â”‚ keywords        â”‚        â”‚ created_at              â”‚
â”‚ content_hash    â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ created_at      â”‚
â”‚ updated_at      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   fetch_logs    â”‚        â”‚    system_metrics       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)         â”‚        â”‚ id (PK)                 â”‚
â”‚ source_type     â”‚        â”‚ metric_name             â”‚
â”‚ source_url      â”‚        â”‚ metric_value            â”‚
â”‚ fetch_count     â”‚        â”‚ timestamp               â”‚
â”‚ success_count   â”‚        â”‚ metadata                â”‚
â”‚ error_count     â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ last_fetch_time â”‚
â”‚ status          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ«ãƒ¼ãƒ«

1. **è¨˜äº‹ã®ä¸€æ„æ€§**: `url` ãŠã‚ˆã³ `content_hash` ã«ã‚ˆã‚‹é‡è¤‡é˜²æ­¢
2. **å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„**: çµ„ã¿åˆã‚ã›ææ¡ˆã¯æœ‰åŠ¹ãªè¨˜äº‹IDã‚’å‚ç…§
3. **ãƒ‡ãƒ¼ã‚¿å‹æ¤œè¨¼**: æ—¥ä»˜ã€ã‚¹ã‚³ã‚¢ãªã©ã®å‹åˆ¶ç´„
4. **NULLåˆ¶ç´„**: å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®NULLé˜²æ­¢

## ğŸ”€ ä¸¦è¡Œå‡¦ç†è¨­è¨ˆ

### éåŒæœŸå‡¦ç†æˆ¦ç•¥

```python
# ä¸¦è¡Œãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†
async def fetch_all_sources():
    tasks = [
        fetch_rss_feeds(),
        scrape_websites(),
        fetch_api_data()
    ]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return consolidate_results(results)

# ã‚»ãƒãƒ•ã‚©ã«ã‚ˆã‚‹åŒæ™‚æ¥ç¶šæ•°åˆ¶å¾¡
semaphore = asyncio.Semaphore(5)  # æœ€å¤§5ä¸¦è¡Œæ¥ç¶š

async def fetch_with_limit(url):
    async with semaphore:
        return await fetch_url(url)
```

### ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼åˆ¶å¾¡

- ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã®åˆ¶é™
- å‡¦ç†é€Ÿåº¦ã®ç›£è¦–
- è‡ªå‹•çš„ãªè² è·èª¿æ•´

## ğŸ”§ è¨­å®šç®¡ç†

### éšå±¤çš„è¨­å®š

```python
# config/default.yaml
database:
  path: "ai_news.db"
  backup_enabled: true
  
fetcher:
  timeout: 30
  max_articles_per_source: 50
  
analyzer:
  min_keywords: 1
  confidence_threshold: 0.5
```

### ç’°å¢ƒåˆ¥è¨­å®š

- `config/development.yaml`
- `config/production.yaml`
- `config/testing.yaml`

## ğŸ§ª ãƒ†ã‚¹ãƒˆè¨­è¨ˆ

### ãƒ†ã‚¹ãƒˆãƒ”ãƒ©ãƒŸãƒƒãƒ‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    E2E Tests        â”‚  â†â”€â”€ å°‘æ•°ã€é‡è¦ãƒ•ãƒ­ãƒ¼
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Integration Tests  â”‚  â†â”€â”€ ä¸­ç¨‹åº¦ã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    Unit Tests       â”‚  â†â”€â”€ å¤šæ•°ã€å€‹åˆ¥æ©Ÿèƒ½
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

**å˜ä½“ãƒ†ã‚¹ãƒˆ**:
- å„ã‚¯ãƒ©ã‚¹ã®ãƒ¡ã‚½ãƒƒãƒ‰å˜ä½
- ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ãŸå¤–éƒ¨ä¾å­˜ã®åˆ†é›¢
- ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ç¶²ç¾…

**çµ±åˆãƒ†ã‚¹ãƒˆ**:
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆ
- å¤–éƒ¨APIçµ±åˆ
- ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ•ãƒ­ãƒ¼

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ**:
- è² è·ãƒ†ã‚¹ãƒˆ
- ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
- ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ

## ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­è¨ˆ

### è„…å¨ãƒ¢ãƒ‡ãƒ«

1. **SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªã§é˜²å¾¡
2. **XSS**: å‡ºåŠ›ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã§é˜²å¾¡
3. **CSRF**: ãƒˆãƒ¼ã‚¯ãƒ³ãƒ™ãƒ¼ã‚¹èªè¨¼ã§é˜²å¾¡
4. **Rate Limiting**: APIä½¿ç”¨é‡åˆ¶é™ã§é˜²å¾¡

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–

```python
# SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–
cursor.execute("SELECT * FROM articles WHERE id = ?", (article_id,))

# URLæ¤œè¨¼
from urllib.parse import urlparse
def is_valid_url(url):
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except:
        return False

# Rate Limiting
from time import time
from collections import defaultdict

class RateLimiter:
    def __init__(self, max_requests=100, window=3600):
        self.max_requests = max_requests
        self.window = window
        self.requests = defaultdict(list)
    
    def is_allowed(self, identifier):
        now = time()
        # å¤ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‰Šé™¤
        self.requests[identifier] = [
            req_time for req_time in self.requests[identifier]
            if now - req_time < self.window
        ]
        
        if len(self.requests[identifier]) < self.max_requests:
            self.requests[identifier].append(now)
            return True
        return False
```

## ğŸ“Š ç›£è¦–ãƒ»ãƒ­ã‚°è¨­è¨ˆ

### ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

```python
# ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
from dataclasses import dataclass
from datetime import datetime

@dataclass
class SystemMetrics:
    articles_fetched: int
    processing_time: float
    error_count: int
    memory_usage: float
    timestamp: datetime

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å™¨
class MetricsCollector:
    def __init__(self):
        self.metrics = []
    
    def record_metric(self, name: str, value: float, tags: dict = None):
        metric = {
            'name': name,
            'value': value,
            'tags': tags or {},
            'timestamp': datetime.now()
        }
        self.metrics.append(metric)
```

### ãƒ­ã‚°æˆ¦ç•¥

- **æ§‹é€ åŒ–ãƒ­ã‚°**: JSONå½¢å¼ã§ã®å‡ºåŠ›
- **ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«**: DEBUG, INFO, WARN, ERROR
- **ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³**: ã‚µã‚¤ã‚ºãƒ™ãƒ¼ã‚¹ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- **ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¼ã‚¿**: è‡ªå‹•ãƒã‚¹ã‚­ãƒ³ã‚°

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤è¨­è¨ˆ

### ã‚³ãƒ³ãƒ†ãƒŠåŒ–

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
CMD ["python", "ai_news_integrated_system.py"]
```

### ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

```yaml
# docker-compose.yml
version: '3.8'
services:
  ai-news-dig:
    build: .
    environment:
      - DB_PATH=/data/ai_news.db
    volumes:
      - ./data:/data
    restart: unless-stopped
```

### CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

1. **ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰å¤‰æ›´**
2. **è‡ªå‹•ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ**
3. **ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª**
4. **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³**
5. **Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰**
6. **ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤**
7. **E2E ãƒ†ã‚¹ãƒˆ**
8. **ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤**

## ğŸ”„ é‹ç”¨è¨­è¨ˆ

### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥

- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: æ—¥æ¬¡ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
- **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
- **ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«**: åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–

### ç½å®³å¾©æ—§

- **RTO**: 4æ™‚é–“ä»¥å†…
- **RPO**: 24æ™‚é–“ä»¥å†…
- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ**: æœˆæ¬¡å®Ÿæ–½

### å®¹é‡è¨ˆç”»

```python
# å®¹é‡è¦‹ç©ã‚‚ã‚Š
articles_per_day = 1000
average_article_size = 2048  # bytes
daily_growth = articles_per_day * average_article_size
monthly_growth = daily_growth * 30
yearly_growth = monthly_growth * 12

print(f"å¹´é–“ãƒ‡ãƒ¼ã‚¿å¢—åŠ é‡: {yearly_growth / (1024**3):.2f} GB")
```
"""
    
    with open("docs/system_design.md", "w", encoding="utf-8") as f:
        f.write(system_design)
    
    print("âœ… docs/system_design.md ã‚’ä½œæˆã—ã¾ã—ãŸ")
    
    # 5. requirements.txt ã®æ”¹å–„
    print("ğŸ“ 5. requirements.txt ã®æ”¹å–„ä¸­...")
    
    requirements_content = """# AI News Dig - ä¾å­˜é–¢ä¿‚

# Core dependencies
requests>=2.31.0
feedparser>=6.0.10
aiohttp>=3.8.5
beautifulsoup4>=4.12.2

# Database
sqlite3  # Built-in with Python

# Development dependencies
pytest>=7.4.0
pytest-asyncio>=0.21.1
pytest-cov>=4.1.0
black>=23.7.0
flake8>=6.0.0
mypy>=1.5.0

# Optional dependencies for extended functionality
# spacy>=3.6.1  # For advanced NLP
# nltk>=3.8.1   # For text processing
# pandas>=2.0.3 # For data analysis
# numpy>=1.24.3 # For numerical computations

# Security
safety>=2.3.4
bandit>=1.7.5
"""
    
    with open("requirements.txt", "w", encoding="utf-8") as f:
        f.write(requirements_content)
    
    print("âœ… requirements.txt ã‚’æ”¹å–„ã—ã¾ã—ãŸ")
    
    # 6. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰ç”Ÿæˆ
    print("ğŸ“ 6. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰ç”Ÿæˆä¸­...")
    
    troubleshooting = """# AI News Dig - ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰

## ğŸš¨ ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«é–¢é€£

#### å•é¡Œ: `pip install` ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹

```bash
ERROR: Could not find a version that satisfies the requirement...
```

**è§£æ±ºæ–¹æ³•:**
1. Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèª (3.9ä»¥ä¸ŠãŒå¿…è¦)
```bash
python --version
```

2. pip ã‚’æœ€æ–°ç‰ˆã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
```bash
pip install --upgrade pip
```

3. ä»®æƒ³ç’°å¢ƒã‚’ä½¿ç”¨
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ã¾ãŸã¯
venv\\Scripts\\activate  # Windows
```

#### å•é¡Œ: SSLè¨¼æ˜æ›¸ã‚¨ãƒ©ãƒ¼

```bash
SSL: CERTIFICATE_VERIFY_FAILED
```

**è§£æ±ºæ–¹æ³•:**
1. è¨¼æ˜æ›¸ã‚’æ›´æ–°
```bash
# Mac
/Applications/Python\\ 3.x/Install\\ Certificates.command

# Linux
sudo apt-get update && sudo apt-get install ca-certificates
```

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é–¢é€£

#### å•é¡Œ: `sqlite3.OperationalError: database is locked`

**åŸå› :** ä»–ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­

**è§£æ±ºæ–¹æ³•:**
1. ä»–ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¢ºèªãƒ»çµ‚äº†
```bash
ps aux | grep python
kill <process_id>
```

2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¨©é™ç¢ºèª
```bash
ls -la ai_news.db
chmod 664 ai_news.db
```

#### å•é¡Œ: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒç ´æã—ã¦ã„ã‚‹

**ç—‡çŠ¶:**
```bash
sqlite3.DatabaseError: database disk image is malformed
```

**è§£æ±ºæ–¹æ³•:**
1. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ
```bash
cp ai_news.db.backup ai_news.db
```

2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å†æ§‹ç¯‰
```python
import os
from ai_news_database import AINewsDatabase

# ç ´æã—ãŸDBã‚’å‰Šé™¤
os.remove("ai_news.db")

# æ–°ã—ã„DBã‚’ä½œæˆ
db = AINewsDatabase()
```

### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é–¢é€£

#### å•é¡Œ: ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚§ãƒƒãƒã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼

```bash
aiohttp.ServerTimeoutError: Timeout on reading data from socket
```

**è§£æ±ºæ–¹æ³•:**
1. ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã‚’å¢—åŠ 
```python
# ai_news_fetcher.py ã§è¨­å®šå¤‰æ›´
FETCH_TIMEOUT = 60  # 30ã‹ã‚‰60ã«å¤‰æ›´
```

2. ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã®ç¢ºèª
```python
# ãƒ—ãƒ­ã‚­ã‚·ç’°å¢ƒã§ã®è¨­å®š
import os
os.environ['HTTP_PROXY'] = 'http://proxy.example.com:8080'
os.environ['HTTPS_PROXY'] = 'https://proxy.example.com:8080'
```

#### å•é¡Œ: RSS ãƒ•ã‚£ãƒ¼ãƒ‰ãŒå–å¾—ã§ããªã„

**ç—‡çŠ¶:**
```bash
feedparser.parse() returns empty entries
```

**è§£æ±ºæ–¹æ³•:**
1. User-Agent ã‚’è¨­å®š
```python
import feedparser
feedparser.USER_AGENT = "AI-News-Dig/1.0"
```

2. æ‰‹å‹•ã§RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ç¢ºèª
```bash
curl -H "User-Agent: AI-News-Dig/1.0" "https://example.com/rss"
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–¢é€£

#### å•é¡Œ: å‡¦ç†ãŒéå¸¸ã«é…ã„

**åŸå› :** å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚„éåŠ¹ç‡ãªã‚¯ã‚¨ãƒª

**è§£æ±ºæ–¹æ³•:**
1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
```sql
CREATE INDEX idx_articles_created_at ON news_articles(created_at);
CREATE INDEX idx_articles_source ON news_articles(source);
```

2. ä¸¦è¡Œå‡¦ç†æ•°ã®èª¿æ•´
```python
# ai_news_fetcher.py
MAX_CONCURRENT_REQUESTS = 3  # 5ã‹ã‚‰3ã«å‰Šæ¸›
```

3. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–
```python
import psutil
import os

process = psutil.Process(os.getpid())
memory_info = process.memory_info()
print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_info.rss / 1024 / 1024:.2f} MB")
```

#### å•é¡Œ: ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

```bash
MemoryError: Unable to allocate array
```

**è§£æ±ºæ–¹æ³•:**
1. ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
```python
# ä¸€åº¦ã«å‡¦ç†ã™ã‚‹è¨˜äº‹æ•°ã‚’åˆ¶é™
BATCH_SIZE = 50  # 100ã‹ã‚‰50ã«å‰Šæ¸›
```

2. ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®æ˜ç¤ºçš„å®Ÿè¡Œ
```python
import gc
gc.collect()
```

### åˆ†æé–¢é€£

#### å•é¡Œ: çµ„ã¿åˆã‚ã›ææ¡ˆãŒç”Ÿæˆã•ã‚Œãªã„

**åŸå› :** å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„

**è§£æ±ºæ–¹æ³•:**
1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’æ‹¡å¼µ
```python
# ã‚ˆã‚Šå¤šãã®AIé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ 
ai_keywords.extend([
    'automation', 'algorithm', 'data science',
    'neural', 'cognitive', 'smart'
])
```

2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã®ãƒ‡ãƒãƒƒã‚°
```python
def debug_keywords(article):
    keywords = extract_keywords(article)
    print(f"Article: {article['title'][:50]}...")
    print(f"Keywords: {keywords}")
    return keywords
```

#### å•é¡Œ: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ãŒä½ã„

**è§£æ±ºæ–¹æ³•:**
1. ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®èª¿æ•´
```python
def calculate_confidence_score(common_keywords, article1, article2):
    base_score = len(common_keywords) * 0.2
    # è¨˜äº‹ã®æ–°ã—ã•ã‚’è€ƒæ…®
    recency_bonus = 0.1 if is_recent(article1, article2) else 0
    return min(base_score + recency_bonus, 1.0)
```

## ğŸ”§ ãƒ‡ãƒãƒƒã‚°ãƒ„ãƒ¼ãƒ«

### ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®å¤‰æ›´

```python
import logging

# ãƒ‡ãƒãƒƒã‚°ãƒ¬ãƒ™ãƒ«ã®ãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ–
logging.basicConfig(level=logging.DEBUG)

# ç‰¹å®šã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
logging.getLogger('ai_news_fetcher').setLevel(logging.DEBUG)
```

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç›´æ¥ç¢ºèª

```bash
# SQLiteã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«
sqlite3 ai_news.db

# ã‚ˆãä½¿ã†ã‚¯ã‚¨ãƒª
.tables
SELECT COUNT(*) FROM news_articles;
SELECT source, COUNT(*) FROM news_articles GROUP BY source;
SELECT * FROM news_articles ORDER BY created_at DESC LIMIT 5;
```

### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã®ãƒ†ã‚¹ãƒˆ

```python
import asyncio
import aiohttp

async def test_connection(url):
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                print(f"Status: {response.status}")
                print(f"Headers: {response.headers}")
                return True
    except Exception as e:
        print(f"Connection failed: {e}")
        return False

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
asyncio.run(test_connection("https://example.com/rss"))
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

### å®Ÿè¡Œæ™‚é–“ã®æ¸¬å®š

```python
import time
from functools import wraps

def timing_decorator(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start = time.time()
        result = await func(*args, **kwargs)
        end = time.time()
        print(f"{func.__name__} took {end - start:.2f} seconds")
        return result
    return wrapper

@timing_decorator
async def fetch_all_news():
    # å®Ÿè£…
    pass
```

### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–

```python
import tracemalloc

# ãƒ¡ãƒ¢ãƒªãƒˆãƒ¬ãƒ¼ã‚¹é–‹å§‹
tracemalloc.start()

# å‡¦ç†å®Ÿè¡Œ
await run_system()

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¡¨ç¤º
current, peak = tracemalloc.get_traced_memory()
print(f"Current memory usage: {current / 1024 / 1024:.2f} MB")
print(f"Peak memory usage: {peak / 1024 / 1024:.2f} MB")
tracemalloc.stop()
```

## ğŸ†˜ ç·Šæ€¥æ™‚ã®å¯¾å¿œ

### ã‚·ã‚¹ãƒ†ãƒ åœæ­¢æ‰‹é †

1. å®Ÿè¡Œä¸­ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¢ºèª
```bash
ps aux | grep python
```

2. å®‰å…¨ã«ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢
```bash
# GRACEFULãªåœæ­¢
kill -TERM <process_id>

# å¼·åˆ¶åœæ­¢ï¼ˆæœ€å¾Œã®æ‰‹æ®µï¼‰
kill -KILL <process_id>
```

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

```bash
# ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
cp ai_news.db ai_news_backup_$(date +%Y%m%d_%H%M%S).db

# SQLãƒ€ãƒ³ãƒ—ã§ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
sqlite3 ai_news.db .dump > backup.sql
```

### ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§æ‰‹é †

1. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒ
```bash
cp ai_news_backup_latest.db ai_news.db
```

2. ä¾å­˜é–¢ä¿‚ã®å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
pip install -r requirements.txt --force-reinstall
```

3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
```bash
sqlite3 ai_news.db "PRAGMA integrity_check;"
```

## ğŸ“ ã‚µãƒãƒ¼ãƒˆæƒ…å ±

### ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´æ‰€
- å®Ÿè¡Œãƒ­ã‚°: `./logs/ai_news_system.log`
- ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°: `./logs/errors.log`
- ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: `./logs/debug.log`

### ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã®åé›†

```python
import sys
import platform
import sqlite3

def collect_system_info():
    info = {
        'python_version': sys.version,
        'platform': platform.platform(),
        'sqlite_version': sqlite3.sqlite_version,
        'system_time': datetime.now().isoformat()
    }
    return info
```

### å•é¡Œå ±å‘Šæ™‚ã«å«ã‚ã‚‹æƒ…å ±

1. ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å®Œå…¨ãªã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹
2. å®Ÿè¡Œç’°å¢ƒï¼ˆOSã€Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
3. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ï¼ˆã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–æƒ…å ±ã¯é™¤ãï¼‰
4. å®Ÿè¡Œæ™‚ã®ãƒ­ã‚°
5. å†ç¾æ‰‹é †

---

**å•é¡ŒãŒè§£æ±ºã—ãªã„å ´åˆã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚**
"""
    
    with open("docs/troubleshooting.md", "w", encoding="utf-8") as f:
        f.write(troubleshooting)
    
    print("âœ… docs/troubleshooting.md ã‚’ä½œæˆã—ã¾ã—ãŸ")
    
    # 7. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°
    print("ğŸ“ 7. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆã‚’æœ€çµ‚ç¢ºèªä¸­...")
    
    print("\nğŸ‰ ai-news-digãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å‚™ãŒå®Œäº†ã—ã¾ã—ãŸ!")
    print("\nğŸ“š ä½œæˆã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:")
    print("  âœ… README.md - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ã¨ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ")
    print("  âœ… docs/technical_specification.md - æŠ€è¡“ä»•æ§˜æ›¸")
    print("  âœ… docs/api_reference.md - APIè©³ç´°ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹") 
    print("  âœ… docs/system_design.md - ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
    print("  âœ… docs/troubleshooting.md - ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰")
    print("  âœ… requirements.txt - æ”¹å–„ã•ã‚ŒãŸä¾å­˜é–¢ä¿‚")
    
    # æœ€çµ‚çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆã‚’è¡¨ç¤º
    print("\nğŸ“ æœ€çµ‚çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ:")
    
    import subprocess
    result = subprocess.run(["find", target_project, "-type", "f", "-name", "*.py", "-o", "-name", "*.md", "-o", "-name", "*.txt"], 
                           capture_output=True, text=True)
    
    if result.returncode == 0:
        files = result.stdout.strip().split('\n')
        for file in sorted(files):
            if file:
                rel_path = file.replace(target_project + "/", "")
                print(f"  ğŸ“„ {rel_path}")
    
    print(f"\nğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…¨å®¹ãŒå®Œå…¨ã«æ–‡æ›¸åŒ–ã•ã‚Œã¾ã—ãŸï¼")

if __name__ == "__main__":
    generate_comprehensive_documentation()